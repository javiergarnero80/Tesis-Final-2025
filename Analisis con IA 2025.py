import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.ticker import FuncFormatter
from pathlib import Path
import logging
from time import sleep
from geopy.geocoders import Nominatim
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVR
from sklearn.feature_extraction.text import TfidfVectorizer
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
import unicodedata
import re
import folium
import webbrowser
import tensorflow as tf
import numpy as np
import requests
import os

# Logging configuration
logging.basicConfig(level=logging.INFO,
                   format='%(asctime)s - %(levelname)s - %(message)s')

# Directorio de salida
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Carpeta espec√≠fica para figuras de la tesis
FIGS_TESIS_DIR = OUTPUT_DIR / "figs_tesis"
FIGS_TESIS_DIR.mkdir(parents=True, exist_ok=True)

def human_readable_magnitude(value, _):
    """Formatea valores num√©ricos con sufijos (K, M, B) para ejes acad√©micos."""
    abs_value = abs(value)
    if abs_value >= 1_000_000_000:
        return f"{value / 1_000_000_000:.1f}B"
    if abs_value >= 1_000_000:
        return f"{value / 1_000_000:.1f}M"
    if abs_value >= 1_000:
        return f"{value / 1_000:.1f}K"
    return f"{value:,.0f}"

def bootstrap_mean_ci(series, n_boot=2000, ci=95, rng=None):
    """
    Calcula un intervalo de confianza bootstrap para la media de una serie.

    Parameters
    ----------
    series : pandas.Series
        Serie num√©rica sin valores NaN para replicar.
    n_boot : int, optional
        Cantidad de r√©plicas bootstrap a generar. Por defecto 2000.
    ci : int, optional
        Nivel de confianza (en porcentaje). Por defecto 95.
    rng : numpy.random.Generator, optional
        Generador de n√∫meros aleatorios para reproducibilidad.

    Returns
    -------
    tuple[float, float]
        Valores (lower, upper) correspondientes al intervalo de confianza.
    """
    clean_data = series.dropna().to_numpy()
    if clean_data.size == 0:
        return (np.nan, np.nan)

    rng = rng or np.random.default_rng(42)
    resamples = rng.choice(clean_data, size=(n_boot, clean_data.size), replace=True)
    boot_means = resamples.mean(axis=1)
    alpha = (100 - ci) / 2
    lower = np.percentile(boot_means, alpha)
    upper = np.percentile(boot_means, 100 - alpha)
    return (lower, upper)

def sumar_columnas(df, cols):
    """Genera reportes visuales y opcionalmente guarda gr√°ficos estad√≠sticos para columnas num√©ricas.

    Par√°metros:
        df (pandas.DataFrame): DataFrame con los datos a analizar.
        cols (list): Lista de columnas num√©ricas a analizar.

    Descripci√≥n:
        Esta funci√≥n muestra 4 gr√°ficos acad√©micos sobre los datos num√©ricos en una figura con 4 subplots:
        1. Fig01_totales.png: Barras de totales acumulados (ordenadas de mayor a menor).
        2. Fig02_promedios.png: Barras de promedios con intervalos de confianza al 95%.
        3. Fig03_cv.png: Coeficiente de variaci√≥n por variable.
        4. Fig04_min_prom_max.png: Comparaci√≥n Min-Promedio-M√°ximo.

        Los gr√°ficos se muestran en pantalla en una sola ventana. Despu√©s, se pide confirmaci√≥n en consola para guardar.
        Si se responde 's', se solicita carpeta de destino y se guardan a 300 dpi.
        Si 'n', no se guarda nada.
        Estilo gr√°fico acad√©mico: barras ordenadas mayor a menor, ejes con K/M/B, t√≠tulos y etiquetas claras, colores sobrios (azul, verde, gris).

    Notas:
        - Utiliza bootstrap para calcular intervalos de confianza del 95%.
        - Maneja errores de entrada y proporciona validaciones robustas.
        - Adecuado para tesis acad√©micas y an√°lisis profesional.
    """
    # Validar la entrada y quedarnos solo con las columnas num√©ricas disponibles en el DataFrame.
    if df is None or df.empty:
        raise ValueError("El DataFrame no contiene informaci√≥n para analizar.")

    numeric_cols = [col for col in cols if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]
    if not numeric_cols:
        raise ValueError("La lista de columnas no contiene variables num√©ricas v√°lidas.")

    data = df[numeric_cols].dropna()
    if data.empty:
        raise ValueError("No hay registros completos disponibles para las columnas indicadas.")

    # Preparar estilo y orden de las variables por importancia (suma descendente).
    sns.set_theme(style="whitegrid", context="notebook")  # Mejor para tesis
    plt.rcParams['font.family'] = 'serif'  # Fuente serif acad√©mica
    plt.rcParams['font.size'] = 10  # Tama√±o de fuente consistente
    totals = data.sum().sort_values(ascending=False)
    ordered_cols = totals.index.tolist()

    # Calcular estad√≠sticos claves alineados al orden definido.
    means = data[ordered_cols].mean()
    stds = data[ordered_cols].std()
    mean_safe = means.replace(0, np.nan)  # Evita divisiones por cero al calcular el CV.
    cv = (stds / mean_safe) * 100
    mins = data[ordered_cols].min()
    maxs = data[ordered_cols].max()

    # Configurar formato de etiquetas del eje X.
    def _format_xticklabels(axis):
        for label in axis.get_xticklabels():
            label.set_rotation(45)
            label.set_horizontalalignment('right')
            label.set_fontsize(9)

    # Calcular intervalos de confianza bootstrap para cada columna.
    lower_errors = []
    upper_errors = []
    for col in ordered_cols:
        lower_ci, upper_ci = bootstrap_mean_ci(data[col])
        lower_errors.append(max(0, means[col] - lower_ci) if not np.isnan(lower_ci) else 0)
        upper_errors.append(max(0, upper_ci - means[col]) if not np.isnan(upper_ci) else 0)

    # Configurar matplotlib para modo interactivo y evitar bloqueo de tkinter
    plt.ion()  # Activar modo interactivo
    plt.show(block=False)  # No bloquear

    # Crear figura √∫nica con 4 subplots para mostrar todos los gr√°ficos juntos.
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle("An√°lisis Estad√≠stico Integral de Variables Num√©ricas", fontsize=18, fontweight='bold', y=0.98)

    # Subplot 1: Totales acumulados por columna (ordenados descendente).
    bars1 = ax1.bar(ordered_cols, totals.values, color="#4C72B0", edgecolor="black", alpha=0.9)
    ax1.set_title("a) Totales acumulados por variable", fontsize=14, fontweight='bold', pad=20)
    ax1.set_xlabel("Variables num√©ricas", fontsize=11)
    ax1.set_ylabel("Totales", fontsize=11)
    ax1.yaxis.set_major_formatter(FuncFormatter(human_readable_magnitude))
    ax1.grid(axis='y', linestyle='--', alpha=0.5)
    ax1.margins(x=0.05)
    _format_xticklabels(ax1)
    for bar in bars1:
        height = bar.get_height()
        ax1.annotate(human_readable_magnitude(height, None),
                     xy=(bar.get_x() + bar.get_width() / 2, height),
                     xytext=(0, 7), textcoords="offset points",
                     ha='center', va='bottom', fontsize=9, fontweight='bold')

    # Subplot 2: Promedios con intervalo de confianza al 95%.
    bars2 = ax2.bar(ordered_cols, means.values, color="#55A868", edgecolor="black", alpha=0.9,
                    yerr=[lower_errors, upper_errors], capsize=4, ecolor="#2E8B57")
    ax2.set_title("b) Promedios con intervalo de confianza 95%", fontsize=14, fontweight='bold', pad=20)
    ax2.set_xlabel("Variables num√©ricas", fontsize=11)
    ax2.set_ylabel("Promedios", fontsize=11)
    ax2.yaxis.set_major_formatter(FuncFormatter(human_readable_magnitude))
    ax2.grid(axis='y', linestyle='--', alpha=0.5)
    ax2.margins(x=0.05)
    _format_xticklabels(ax2)
    for bar in bars2:
        height = bar.get_height()
        if height > 0:
            ax2.annotate(human_readable_magnitude(height, None),
                         xy=(bar.get_x() + bar.get_width() / 2, height),
                         xytext=(0, 7), textcoords="offset points",
                         ha='center', va='bottom', fontsize=9, fontweight='bold')

    # Subplot 3: Coeficiente de variaci√≥n.
    bars3 = ax3.bar(ordered_cols, cv.values, color="#7F7F7F", edgecolor="black", alpha=0.9)
    ax3.set_title("c) Coeficiente de variaci√≥n", fontsize=14, fontweight='bold', pad=20)
    ax3.set_xlabel("Variables num√©ricas", fontsize=11)
    ax3.set_ylabel("CV (%)", fontsize=11)
    ax3.grid(axis='y', linestyle='--', alpha=0.5)
    ax3.margins(x=0.05)
    _format_xticklabels(ax3)
    ax3.axhline(y=50, color="#4C72B0", linestyle="--", linewidth=2, alpha=0.8, label="Variabilidad moderada")
    ax3.axhline(y=100, color="#55A868", linestyle="--", linewidth=2, alpha=0.8, label="Alta variabilidad")
    ax3.legend(fontsize=9, loc='upper right')
    for bar in bars3:
        height = bar.get_height()
        ax3.annotate(f"{height:.1f}%", xy=(bar.get_x() + bar.get_width() / 2, height),
                     xytext=(0, 7), textcoords="offset points",
                     ha='center', va='bottom', fontsize=9, fontweight='bold')

    # Subplot 4: Comparaci√≥n Min-Promedio-M√°ximo con barras agrupadas.
    width = 0.25
    x_pos = np.arange(len(ordered_cols))
    ax4.bar(x_pos - width, mins.values, width, label="M√≠nimo", color="#4C72B0", edgecolor="black", alpha=0.9)
    ax4.bar(x_pos, means.values, width, label="Promedio", color="#55A868", edgecolor="black", alpha=0.9)
    ax4.bar(x_pos + width, maxs.values, width, label="M√°ximo", color="#7F7F7F", edgecolor="black", alpha=0.9)
    ax4.set_title("d) Comparaci√≥n.min-prm-max", fontsize=14, fontweight='bold', pad=20)
    ax4.set_xlabel("Variables num√©ricas", fontsize=11)
    ax4.set_ylabel("Valores", fontsize=11)
    ax4.yaxis.set_major_formatter(FuncFormatter(human_readable_magnitude))
    ax4.set_xticks(x_pos)
    ax4.set_xticklabels(ordered_cols, rotation=45, ha='right')
    ax4.grid(axis='y', linestyle='--', alpha=0.5)
    ax4.legend(fontsize=9, loc='upper left')
    ax4.margins(x=0.05)

    # Ajustar layout para evitar superposiciones.
    fig.tight_layout()
    plt.subplots_adjust(top=0.88, hspace=0.4, wspace=0.25)

    # Mostrar la figura completa con los 4 gr√°ficos.
    plt.show()

    # Consultar al usuario si desea guardar los gr√°ficos.
    respuesta = input("¬øDesea guardar los gr√°ficos como PNG? (s/n): ").strip().lower()
    while respuesta not in {"s", "n"}:
        respuesta = input("Respuesta no v√°lida. Ingrese 's' para s√≠ o 'n' para no: ").strip().lower()

    if respuesta == "s":
        carpeta = input("Ingrese la carpeta donde desea guardar los gr√°ficos: ").strip()
        while not carpeta:
            carpeta = input("La ruta no puede estar vac√≠a. Ingrese la carpeta destino: ").strip()
        destino = Path(carpeta).expanduser()
        destino.mkdir(parents=True, exist_ok=True)
        for nombre, figura in figures:
            figura.savefig(destino / nombre, dpi=300, bbox_inches='tight')
        print(f"Gr√°ficos guardados en {destino}")
    else:
        print("Los gr√°ficos no se guardaron.")

    # Cerrar las figuras para liberar memoria en sesiones iterativas.
    for _, figura in figures:
        plt.close(figura)


# Geolocalizador con configuraci√≥n mejorada
geolocator = Nominatim(user_agent="analisis_agricola_app/1.0")

class FileHandler:
    """Clase para manejar la carga y validaci√≥n de archivos CSV."""

    @staticmethod
    def cargar_csv():
        """Carga un archivo CSV en un DataFrame de pandas."""
        file_path = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv")])
        if file_path:
            try:
                df = pd.read_csv(file_path)
                df.columns = df.columns.str.strip()  # Limpiar espacios en blanco de los nombres de columnas
                # Normalizar nombres de columnas para manejar acentos y may√∫sculas/min√∫sculas
                df.columns = df.columns.str.normalize('NFD').str.encode('ascii', 'ignore').str.decode('utf-8').str.lower()
                logging.info(f"Archivo CSV cargado: {file_path}")
                messagebox.showinfo("Cargar CSV", "Archivo CSV cargado exitosamente.")
                return df
            except pd.errors.EmptyDataError:
                logging.error("El archivo CSV est√° vac√≠o.")
                messagebox.showerror("Error", "El archivo CSV est√° vac√≠o.")
            except pd.errors.ParserError:
                logging.error("Error de an√°lisis en el archivo CSV.")
                messagebox.showerror("Error", "Error de an√°lisis en el archivo CSV.")
            except Exception as e:
                logging.error(f"Error al cargar el archivo CSV: {e}")
                messagebox.showerror("Error", f"Ocurri√≥ un error al cargar el archivo CSV: {e}")
        return pd.DataFrame()

class DataPreprocessing:
    """Clase para la normalizaci√≥n y preprocesamiento de datos."""

    @staticmethod
    def normalize_text(text):
        """Normaliza el texto eliminando caracteres especiales y acentos."""
        text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')
        text = re.sub(r'[^\w\s]', '', text)  # Elimina caracteres especiales
        text = text.lower().strip()  # Convierte a min√∫sculas y elimina espacios en blanco
        return text

    @staticmethod
    def denormalize_text(normalized_text, original_texts):
        """Denormaliza el texto buscando su versi√≥n original en la lista de textos."""
        for text in original_texts:
            if DataPreprocessing.normalize_text(text) == normalized_text:
                return text
        return None

class Visualization:
    """Clase para la visualizaci√≥n de datos."""

    @staticmethod
    def plot_bar_chart(data, title, xlabel, ylabel, output_file, function_name=""):
        """Genera una gr√°fica de barras."""
        fig = plt.figure(figsize=(12, 8))
        if function_name:
            fig.suptitle(f"{function_name}", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        data.plot(kind='bar', color='skyblue')
        plt.title(title)
        plt.ylabel(ylabel)
        plt.xlabel(xlabel)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(output_file)
        plt.show()
        logging.info(f"Gr√°fica guardada en {output_file}")

class DataAnalyzer:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Aplicaci√≥n de An√°lisis de Datos")
        self.root.geometry("600x400")
        self.df = pd.DataFrame()
        self.setup_menu()
    def _check_csv_loaded(self):
        """Verifica si el CSV est√° cargado y muestra un mensaje si no lo est√°."""
        if self.df.empty:
            messagebox.showwarning("Advertencia", "Por favor cargue un archivo CSV primero.")
            return False
        return True

    def setup_menu(self):
        """Configura el men√∫ de la aplicaci√≥n."""
        self.menu = tk.Menu(self.root)
        self.root.config(menu=self.menu)

        self.file_menu = tk.Menu(self.menu, tearoff=0)
        self.menu.add_cascade(label="Archivo", menu=self.file_menu)
        self.file_menu.add_command(label="Cargar CSV", command=self.cargar_csv)
        self.file_menu.add_command(label="Salir", command=self.root.quit)

        self.analisis_menu = tk.Menu(self.menu, tearoff=0)
        self.menu.add_cascade(label="An√°lisis", menu=self.analisis_menu)
        self.analisis_menu.add_command(label="Sumar Columnas", command=self.sumar_columnas)
        self.analisis_menu.add_command(label="An√°lisis Temporal", command=self.analisis_temporal)
        self.analisis_menu.add_command(label="An√°lisis de Correlaci√≥n", command=self.analisis_correlacion)
        self.analisis_menu.add_command(label="Modelos Predictivos", command=self.modelos_predictivos)
        self.analisis_menu.add_command(label="Clasificaci√≥n de Cultivos", command=self.clasificacion_cultivos)
        self.analisis_menu.add_command(label="An√°lisis de Riesgos", command=self.analisis_riesgos)
        self.analisis_menu.add_command(label="Correlaci√≥n Sup. Sembrada-Sup. Cosechada", command=self.correlacion_sup_sembrada_cosechada)
        self.analisis_menu.add_command(label="Producci√≥n Total por Provincia", command=self.produccion_total_por_provincia)
        self.analisis_menu.add_command(label="Evoluci√≥n de Cultivos por Campa√±a", command=self.evolucion_cultivos_por_campa√±a)
        self.analisis_menu.add_command(label="Tendencias de Producci√≥n por Cultivo", command=self.tendencias_produccion_por_cultivo)
        self.analisis_menu.add_command(label="Predicci√≥n de Tendencias con IA", command=self.prediccion_tendencias_ia)
        self.analisis_menu.add_command(label="An√°lisis Predictivo con Red Neuronal", command=self.analisis_predictivo_nn)
        self.analisis_menu.add_command(label="Producci√≥n Top Cultivos", command=self.produccion_top_cultivos)

        self.geocodificacion_menu = tk.Menu(self.menu, tearoff=0)
        self.menu.add_cascade(label="Geocodificaci√≥n", menu=self.geocodificacion_menu)
        self.geocodificacion_menu.add_command(label="Geocodificar Direcciones", command=self.geocodificar_direcciones)
        self.geocodificacion_menu.add_command(label="Generar Mapa", command=self.generar_mapa)
        self.geocodificacion_menu.add_command(label="Mapa de Distribuci√≥n de Cultivos", command=self.mapa_distribucion_cultivos)

    def cargar_csv(self):
        """Carga un archivo CSV utilizando la clase FileHandler."""
        self.df = FileHandler.cargar_csv()

    def sumar_columnas(self):
        """Realiza un an√°lisis estad√≠stico integral de las variables num√©ricas del dataset agr√≠cola."""
        if not self._check_csv_loaded():
            return

        # Obtener columnas num√©ricas
        numeric_cols = self.df.select_dtypes(include=[float, int]).columns.tolist()

        if not numeric_cols:
            messagebox.showwarning("Advertencia", "No se encontraron columnas num√©ricas para analizar.")
            return

        # Filtrar datos v√°lidos (sin NaN)
        df_numeric = self.df[numeric_cols].dropna()

        if len(df_numeric) < 10:
            messagebox.showwarning("Advertencia", "No hay suficientes datos v√°lidos para el an√°lisis estad√≠stico.")
            return

        # Calcular estad√≠sticas descriptivas completas
        estadisticas = df_numeric.describe()
        suma_columnas = df_numeric.sum()
        mediana_columnas = df_numeric.median()
        desviacion_columnas = df_numeric.std()
        coef_variacion = (desviacion_columnas / df_numeric.mean()) * 100

        # Identificar variables m√°s importantes
        variable_mayor_suma = suma_columnas.idxmax()
        variable_mayor_variabilidad = coef_variacion.idxmax()
        variable_mas_estable = coef_variacion.idxmin()

        # Crear visualizaci√≥n mejorada con m√∫ltiples subgr√°ficos
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

        # Gr√°fico 1: Totales por variable (suma)
        suma_columnas.plot(kind='bar', ax=ax1, color='lightblue', edgecolor='navy')
        ax1.set_title('Totales Acumulados por Variable')
        ax1.set_xlabel('Variables Num√©ricas')
        ax1.set_ylabel('Suma Total')
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(True, alpha=0.3)

        # Agregar valores en las barras
        for i, v in enumerate(suma_columnas.values):
            ax1.text(i, v + v*0.01, f'{v:,.0f}', ha='center', va='bottom', fontsize=8, fontweight='bold')

        # Gr√°fico 2: Promedios por variable
        promedios = df_numeric.mean()
        promedios.plot(kind='bar', ax=ax2, color='lightgreen', edgecolor='darkgreen')
        ax2.set_title('Valores Promedio por Variable')
        ax2.set_xlabel('Variables Num√©ricas')
        ax2.set_ylabel('Promedio')
        ax2.tick_params(axis='x', rotation=45)
        ax2.grid(True, alpha=0.3)

        # Agregar valores en las barras
        for i, v in enumerate(promedios.values):
            ax2.text(i, v + v*0.01, f'{v:,.1f}', ha='center', va='bottom', fontsize=8, fontweight='bold')

        # Gr√°fico 3: Coeficiente de variaci√≥n (estabilidad)
        colores_cv = ['red' if cv > 100 else 'orange' if cv > 50 else 'green' for cv in coef_variacion.values]
        coef_variacion.plot(kind='bar', ax=ax3, color=colores_cv, edgecolor='black')
        ax3.set_title('Coeficiente de Variaci√≥n por Variable (%)')
        ax3.set_xlabel('Variables Num√©ricas')
        ax3.set_ylabel('Coeficiente de Variaci√≥n (%)')
        ax3.tick_params(axis='x', rotation=45)
        ax3.grid(True, alpha=0.3)
        ax3.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Variabilidad Media (50%)')
        ax3.axhline(y=100, color='red', linestyle='--', alpha=0.7, label='Alta Variabilidad (100%)')
        ax3.legend()

        # Agregar valores en las barras
        for i, v in enumerate(coef_variacion.values):
            ax3.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontsize=8, fontweight='bold')

        # Gr√°fico 4: Comparaci√≥n Min-Max-Promedio
        variables_principales = suma_columnas.nlargest(6).index  # Top 6 variables
        df_principales = df_numeric[variables_principales]

        x_pos = np.arange(len(variables_principales))
        width = 0.25

        mins = df_principales.min()
        maxs = df_principales.max()
        means = df_principales.mean()

        ax4.bar(x_pos - width, mins, width, label='M√≠nimo', color='lightcoral', alpha=0.8)
        ax4.bar(x_pos, means, width, label='Promedio', color='lightskyblue', alpha=0.8)
        ax4.bar(x_pos + width, maxs, width, label='M√°ximo', color='lightgreen', alpha=0.8)

        ax4.set_title('Comparaci√≥n Min-Promedio-Max (Top 6 Variables)')
        ax4.set_xlabel('Variables Principales')
        ax4.set_ylabel('Valores')
        ax4.set_xticks(x_pos)
        ax4.set_xticklabels(variables_principales, rotation=45)
        ax4.legend()
        ax4.grid(True, alpha=0.3)

        plt.suptitle("sumar_columnas", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()

        # Guardar gr√°fico
        output_file = OUTPUT_DIR / "analisis_estadistico_integral.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()
        logging.info(f"An√°lisis estad√≠stico integral guardado en {output_file}")

        # An√°lisis de correlaciones entre variables principales
        correlaciones_importantes = []
        if len(variables_principales) > 1:
            corr_matrix = df_principales.corr()
            # Encontrar correlaciones fuertes (>0.7 o <-0.7)
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) > 0.7:
                        var1 = corr_matrix.columns[i]
                        var2 = corr_matrix.columns[j]
                        correlaciones_importantes.append(f"{var1} ‚Üî {var2}: {corr_val:.3f}")

        # Identificar outliers usando el m√©todo IQR
        outliers_info = []
        for col in variables_principales:
            Q1 = df_numeric[col].quantile(0.25)
            Q3 = df_numeric[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = df_numeric[(df_numeric[col] < lower_bound) | (df_numeric[col] > upper_bound)][col]
            if len(outliers) > 0:
                outliers_info.append(f"{col}: {len(outliers)} valores at√≠picos ({len(outliers)/len(df_numeric)*100:.1f}%)")

        # Crear reporte detallado
        correlaciones_texto = "\n".join(correlaciones_importantes[:5]) if correlaciones_importantes else "No se encontraron correlaciones fuertes (>0.7)"
        outliers_texto = "\n".join(outliers_info[:5]) if outliers_info else "No se detectaron valores at√≠picos significativos"

        explanation = (
            "üìä AN√ÅLISIS DE SUMA DE COLUMNAS\n\n"
            "Este an√°lisis suma todas las columnas num√©ricas de tus datos "
            "agr√≠colas y calcula estad√≠sticas b√°sicas.\n\n"
            f"üîç Lo que se analiz√≥: {len(df_numeric):,} registros con datos completos\n"
            f"üìà Columnas num√©ricas encontradas: {len(numeric_cols)}\n\n"
            "üèÜ RESULTADOS PRINCIPALES:\n"
            f"   ‚Ä¢ La columna con mayor suma total es: {variable_mayor_suma} "
            f"(total: {suma_columnas[variable_mayor_suma]:,.0f})\n"
            f"   ‚Ä¢ La columna m√°s variable es: {variable_mayor_variabilidad} (cambia mucho)\n"
            f"   ‚Ä¢ La columna m√°s estable es: {variable_mas_estable} (cambia poco)\n\n"
            "üìä N√öMEROS B√ÅSICOS:\n"
            f"   ‚Ä¢ Promedio general de todas las columnas: {df_numeric.mean().mean():,.1f}\n"
            f"   ‚Ä¢ Valores que se salen de lo normal encontrados: {outliers_texto}\n\n"
            "üí° ¬øQU√â SIGNIFICA ESTO?\n"
            "   ‚Ä¢ Las columnas con n√∫meros m√°s grandes son las m√°s importantes en tus datos\n"
            "   ‚Ä¢ Si una columna cambia mucho, es menos predecible\n"
            "   ‚Ä¢ Los valores at√≠picos pueden ser errores o casos especiales\n\n"
            "üìã PARA QU√â SIRVE:\n"
            "   ‚Ä¢ Saber cu√°les son las variables m√°s importantes\n"
            "   ‚Ä¢ Detectar problemas en los datos\n"
            "   ‚Ä¢ Decidir qu√© analizar primero"
        )

        messagebox.showinfo("An√°lisis Estad√≠stico Integral", f"An√°lisis completado y guardado en {output_file}\n\n{explanation}")

    def analisis_temporal(self):
        """Genera un an√°lisis temporal de la producci√≥n."""
        if not self._check_csv_loaded():
            return
        if 'campa√±a' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener la columna 'campa√±a'.")
            return

        if 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener la columna 'produccion'.")
            return

        # Integraci√≥n del nuevo an√°lisis temporal
        self.df['campa√±a'] = self.df['campa√±a'].astype(str).str.split('/').str[0].astype(int)
        summary_by_campaign = self.df.groupby('campa√±a').agg({
            'sup_sembrada': 'sum',
            'sup_cosechada': 'sum',
            'produccion': 'sum',
            'rendimiento': 'mean'
        }).reset_index()
        summary_by_campaign.sort_values(by='campa√±a', inplace=True)

        plt.figure(figsize=(14, 10))

        # Superficie Sembrada y Cosechada
        plt.subplot(2, 2, 1)
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['sup_sembrada'], label='Superficie Sembrada')
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['sup_cosechada'], label='Superficie Cosechada')
        plt.title('Evoluci√≥n de la Superficie Sembrada y Cosechada')
        plt.xlabel('A√±o de Campa√±a')
        plt.ylabel('Superficie (hect√°reas)')
        plt.legend()

        # Producci√≥n
        plt.subplot(2, 2, 2)
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['produccion'], label='Producci√≥n', color='green')
        plt.title('Evoluci√≥n de la Producci√≥n')
        plt.xlabel('A√±o de Campa√±a')
        plt.ylabel('Producci√≥n (toneladas)')

        # Rendimiento
        plt.subplot(2, 2, 3)
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['rendimiento'], label='Rendimiento', color='orange')
        plt.title('Evoluci√≥n del Rendimiento Promedio')
        plt.xlabel('A√±o de Campa√±a')
        plt.ylabel('Rendimiento (kg/ha)')

        plt.suptitle("analisis_temporal", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()
        plt.show()

    def analisis_correlacion(self):
        """Genera an√°lisis de correlaci√≥n con dise√±o profesional y limpio."""
        if not self._check_csv_loaded():
            return

        numeric_df = self.df.select_dtypes(include=[float, int])
        if numeric_df.empty:
            messagebox.showwarning("Advertencia", "No hay columnas num√©ricas para analizar.")
            return

        # Calcular matriz de correlaci√≥n
        correlation_matrix = numeric_df.corr()

        # Crear figura principal con dise√±o profesional
        fig = plt.figure(figsize=(18, 12), facecolor='white')
        fig.suptitle('AN√ÅLISIS DE CORRELACI√ìN AGR√çCOLA',
                    fontsize=24, fontweight='bold', y=0.95,
                    color='#2C3E50', family='Arial')

        # ==========================================
        # GR√ÅFICO 1: DICCIONARIO LIMPIO Y PROFESIONAL
        # ==========================================
        ax1 = plt.subplot(2, 2, 1)
        ax1.set_facecolor('#F8F9FA')
        ax1.spines['top'].set_visible(False)
        ax1.spines['right'].set_visible(False)
        ax1.spines['left'].set_color('#CCCCCC')
        ax1.spines['bottom'].set_color('#CCCCCC')

        ax1.text(0.5, 0.95, 'GU√çA DE INTERPRETACI√ìN',
                ha='center', va='top', fontsize=16, fontweight='bold', color='#2C3E50')
        ax1.text(0.5, 0.85, 'Aprende a interpretar los coeficientes de correlaci√≥n',
                ha='center', va='top', fontsize=10, color='#7F8C8D')

        # Crear diccionario m√°s limpio y profesional
        correlations_info = [
            ("CORRELACI√ìN POSITIVA FUERTE", "+0.7 a +1.0",
             "Las variables aumentan juntas", "#27AE60"),
            ("CORRELACI√ìN NEGATIVA FUERTE", "-1.0 a -0.7",
             "Cuando una sube, la otra baja", "#E74C3C"),
            ("CORRELACI√ìN MODERADA", "¬±0.3 a ¬±0.7",
             "Relaci√≥n moderada entre variables", "#F39C12"),
            ("CORRELACI√ìN D√âBIL", "-0.3 a +0.3",
             "Las variables act√∫an independientemente", "#95A5A6")
        ]

        y_pos = 0.65
        for name, range_val, description, color in correlations_info:
            # T√≠tulo de la correlaci√≥n
            ax1.text(0.05, y_pos, name, fontsize=11, fontweight='bold', color=color)
            ax1.text(0.55, y_pos, range_val, fontsize=10, color='#2C3E50')

            # Descripci√≥n
            ax1.text(0.05, y_pos - 0.08, description, fontsize=9, color='#34495E')

            # Ejemplo agr√≠cola
            ax1.text(0.05, y_pos - 0.15, "Ejemplo agr√≠cola:", fontsize=9, fontweight='bold', color='#2C3E50')

            y_pos -= 0.25

        ax1.set_xlim(0, 1)
        ax1.set_ylim(0, 1)
        ax1.axis('off')

        # ==========================================
        # GR√ÅFICO 2: MATRIZ DE CORRELACI√ìN PROFESIONAL
        # ==========================================
        ax2 = plt.subplot(2, 2, 2)

        # Seleccionar variables m√°s importantes
        important_vars = []
        for col in correlation_matrix.columns:
            if any(keyword in col.lower() for keyword in ['sup', 'prod', 'rend', 'camp']):
                important_vars.append(col)

        if len(important_vars) >= 2:
            subset_corr = correlation_matrix.loc[important_vars, important_vars]
            matrix_data = subset_corr
            title = 'Variables Principales Agr√≠colas'
        else:
            matrix_data = correlation_matrix
            title = 'Todas las Variables'

        # Crear heatmap m√°s profesional
        mask = np.triu(np.ones_like(matrix_data, dtype=bool))
        sns.heatmap(matrix_data, mask=mask, annot=True, cmap='RdYlBu_r', fmt='.2f',
                   square=True, ax=ax2, cbar_kws={'shrink': 0.8, 'aspect': 20},
                   annot_kws={'fontsize': 10, 'fontweight': 'bold'},
                   linewidths=0.5, linecolor='white')

        ax2.set_title(f'MATRIZ DE CORRELACI√ìN\n{title}', fontsize=14, fontweight='bold', pad=20, color='#2C3E50')
        ax2.tick_params(axis='x', rotation=45, labelsize=9)
        ax2.tick_params(axis='y', labelsize=9)

        # ==========================================
        # GR√ÅFICO 3: TOP RELACIONES M√ÅS IMPORTANTES
        # ==========================================
        ax3 = plt.subplot(2, 2, 3)
        ax3.set_facecolor('#F8F9FA')

        all_correlations = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_val = correlation_matrix.iloc[i, j]
                var1 = correlation_matrix.columns[i]
                var2 = correlation_matrix.columns[j]
                all_correlations.append((var1, var2, corr_val))

        # Ordenar por valor absoluto
        all_correlations.sort(key=lambda x: abs(x[2]), reverse=True)
        top_5 = all_correlations[:5]

        if top_5:
            # Crear etiquetas limpias
            labels = []
            for pair in top_5:
                var1_clean = pair[0].replace('_', ' ').title()
                var2_clean = pair[1].replace('_', ' ').title()
                labels.append(f"{var1_clean}\nvs\n{var2_clean}")

            values = [pair[2] for pair in top_5]

            # Colores profesionales
            colors = ['#27AE60' if v > 0.3 else '#E74C3C' if v < -0.3 else '#F39C12' for v in values]

            bars = ax3.bar(range(len(labels)), values, color=colors, alpha=0.8,
                          edgecolor='white', linewidth=1)

            ax3.set_xticks(range(len(labels)))
            ax3.set_xticklabels(labels, rotation=0, ha='center', fontsize=8, fontweight='bold')
            ax3.set_ylabel('Coeficiente de Correlaci√≥n', fontsize=11, color='#2C3E50')
            ax3.set_title('RELACIONES M√ÅS IMPORTANTES', fontsize=14, fontweight='bold', pad=20, color='#2C3E50')
            ax3.grid(True, alpha=0.3, axis='y', color='white')
            ax3.axhline(y=0, color='#2C3E50', linestyle='-', alpha=0.5, linewidth=1.5)
            ax3.set_ylim(-1.1, 1.1)
            ax3.tick_params(colors='#2C3E50')

            # Agregar valores en barras
            for bar, val in zip(bars, values):
                height = bar.get_height()
                va = 'bottom' if height >= 0 else 'top'
                offset = 0.05 if height >= 0 else -0.05
                ax3.text(bar.get_x() + bar.get_width()/2,
                        height + offset,
                        f'{val:.2f}',
                        ha='center', va=va,
                        fontweight='bold', fontsize=10, color='white',
                        bbox=dict(boxstyle='round,pad=0.2', facecolor=colors[bars.index(bar)], alpha=0.8))

        # ==========================================
        # GR√ÅFICO 4: RECOMENDACIONES PROFESIONALES
        # ==========================================
        ax4 = plt.subplot(2, 2, 4)
        ax4.set_facecolor('#F8F9FA')
        ax4.spines['top'].set_visible(False)
        ax4.spines['right'].set_visible(False)
        ax4.spines['left'].set_visible(False)
        ax4.spines['bottom'].set_visible(False)

        ax4.text(0.5, 0.95, 'RECOMENDACIONES ESTRAT√âGICAS',
                ha='center', va='top', fontsize=16, fontweight='bold', color='#2C3E50')

        # Analizar correlaciones para recomendaciones
        recommendations = []
        for var1, var2, corr in all_correlations[:10]:  # Top 10 correlaciones
            if abs(corr) > 0.5:
                var1_clean = var1.replace('_', ' ').title()
                var2_clean = var2.replace('_', ' ').title()
                strength = "fuerte" if abs(corr) > 0.7 else "moderada"
                direction = "positiva" if corr > 0 else "negativa"
                recommendations.append(f"‚Ä¢ {var1_clean} ‚Üî {var2_clean}: {strength} {direction} ({corr:.2f})")

        # Agregar recomendaciones generales
        recommendations.extend([
            "",
            "ACCIONES RECOMENDADAS:",
            "‚Ä¢ Variables con correlaci√≥n positiva > 0.7: Ideales para predicci√≥n",
            "‚Ä¢ Variables con correlaci√≥n negativa: Considerar trade-offs",
            "‚Ä¢ Variables independientes (< 0.3): √ötiles para diversificar riesgos",
            "",
            "PR√ìXIMOS PASOS:",
            "‚Ä¢ Usar variables altamente correlacionadas para modelos predictivos",
            "‚Ä¢ Investigar causas de correlaciones negativas inesperadas",
            "‚Ä¢ Considerar variables independientes para estrategias de diversificaci√≥n"
        ])

        y_position = 0.85
        for rec in recommendations:
            if rec.startswith("‚Ä¢") or rec.startswith("ACCIONES") or rec.startswith("PR√ìXIMOS"):
                color = '#2C3E50' if rec.startswith("‚Ä¢") else '#E74C3C'
                fontweight = 'bold' if not rec.startswith("‚Ä¢") else 'normal'
                ax4.text(0.05, y_position, rec, fontsize=9, color=color, fontweight=fontweight)
            else:
                ax4.text(0.05, y_position, rec, fontsize=9, color='#34495E')
            y_position -= 0.06

        ax4.set_xlim(0, 1)
        ax4.set_ylim(0, 1)
        ax4.axis('off')

        plt.tight_layout()
        plt.subplots_adjust(top=0.85, hspace=0.3, wspace=0.3)

        correlacion_file = OUTPUT_DIR / "correlacion_profesional.png"
        plt.savefig(correlacion_file, dpi=300, bbox_inches='tight',
                   facecolor='white', edgecolor='none')
        plt.show()
        logging.info(f"An√°lisis profesional de correlaci√≥n guardado en {correlacion_file}")

        # Crear explicaci√≥n profesional
        total_vars = len(correlation_matrix.columns)
        strong_correlations = sum(1 for _, _, corr in all_correlations if abs(corr) > 0.7)
        moderate_correlations = sum(1 for _, _, corr in all_correlations if 0.3 <= abs(corr) <= 0.7)

        explanation = (
            "AN√ÅLISIS DE CORRELACI√ìN PROFESIONAL\n\n"
            f"Variables analizadas: {total_vars}\n"
            f"Correlaciones fuertes (> 0.7): {strong_correlations}\n"
            f"Correlaciones moderadas (0.3-0.7): {moderate_correlations}\n\n"
            "INTERPRETACI√ìN:\n"
            "‚Ä¢ Correlaciones positivas: Las variables se mueven en la misma direcci√≥n\n"
            "‚Ä¢ Correlaciones negativas: Las variables se mueven en direcciones opuestas\n"
            "‚Ä¢ Valores cercanos a 0: Variables independientes\n\n"
            "VALOR PR√ÅCTICO:\n"
            "‚Ä¢ Identificar variables predictoras para modelos de IA\n"
            "‚Ä¢ Descubrir relaciones causales en la producci√≥n agr√≠cola\n"
            "‚Ä¢ Optimizar estrategias de siembra y cosecha\n\n"
            "RECOMENDACIONES:\n"
            "‚Ä¢ Usar variables con correlaci√≥n > 0.7 para predicciones confiables\n"
            "‚Ä¢ Investigar correlaciones negativas para entender limitaciones\n"
            "‚Ä¢ Aprovechar variables independientes para diversificar riesgos"
        )

        messagebox.showinfo("An√°lisis Profesional de Correlaci√≥n",
                           f"An√°lisis completado y guardado en {correlacion_file}\n\n{explanation}")

    def correlacion_sup_sembrada_cosechada(self):
        """
        Calcula y visualiza la correlaci√≥n entre superficie sembrada y cosechada.

        Esta funci√≥n permite seleccionar una provincia y analiza la relaci√≥n
        entre lo sembrado y lo cosechado, proporcionando insights para optimizar
        la eficiencia agr√≠cola.
        """
        if not self._check_csv_loaded():
            return
        if 'provincia' not in self.df.columns or 'sup_sembrada' not in self.df.columns or 'sup_cosechada' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'provincia', 'sup_sembrada' y 'sup_cosechada'.")
            return

        provincias = self.df['provincia'].unique()
        if len(provincias) == 0:
            messagebox.showwarning("Advertencia", "No se encontraron provincias en el archivo CSV.")
            return

        normalized_provincias = [DataPreprocessing.normalize_text(p) for p in provincias]
        selected_provincia_normalized = self.ask_option("Seleccionar Provincia", "Seleccione la provincia:", normalized_provincias)
        selected_provincia = DataPreprocessing.denormalize_text(selected_provincia_normalized, provincias)
        logging.info(f"Provincia seleccionada: {selected_provincia}")

        if not selected_provincia:
            return

        df_provincia = self.df[self.df['provincia'] == selected_provincia]
        df_provincia[['sup_sembrada', 'sup_cosechada']] = df_provincia[['sup_sembrada', 'sup_cosechada']].apply(pd.to_numeric, errors='coerce')
        df_provincia = df_provincia.dropna(subset=['sup_sembrada', 'sup_cosechada'])

        if df_provincia.empty:
            messagebox.showwarning("Advertencia", "No se encontraron datos v√°lidos para calcular la correlaci√≥n.")
            return

        try:
            correlacion = df_provincia[['sup_sembrada', 'sup_cosechada']].corr().iloc[0, 1]
            suggestion = self.get_correlation_suggestion(correlacion)

            # Crear gr√°fico de dispersi√≥n para mayor claridad
            plt.figure(figsize=(8, 6))
            plt.scatter(df_provincia['sup_sembrada'], df_provincia['sup_cosechada'], alpha=0.6, color='blue')
            plt.title(f'Correlaci√≥n entre Superficie Sembrada y Cosechada\nProvincia: {selected_provincia}')
            plt.xlabel('Superficie Sembrada (hect√°reas)')
            plt.ylabel('Superficie Cosechada (hect√°reas)')
            plt.grid(True, alpha=0.3)

            # Agregar l√≠nea de tendencia
            z = np.polyfit(df_provincia['sup_sembrada'], df_provincia['sup_cosechada'], 1)
            p = np.poly1d(z)
            plt.plot(df_provincia['sup_sembrada'], p(df_provincia['sup_sembrada']), "r--", alpha=0.8)

            plt.suptitle("correlacion_sup_sembrada_cosechada", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
            output_file = OUTPUT_DIR / f"correlacion_{self.safe_file_name(selected_provincia)}.png"
            plt.savefig(output_file)
            plt.show()

            explanation = (
                f"La correlaci√≥n entre la superficie sembrada y cosechada en la provincia {selected_provincia} es {correlacion:.2f}. "
                f"{suggestion}\n\n"
                f"üìä Datos analizados: {len(df_provincia)} registros\n"
                f"üìà Gr√°fico guardado en: {output_file}"
            )
            messagebox.showinfo("Correlaci√≥n Sup. Sembrada-Sup. Cosechada", explanation)
        except Exception as e:
            logging.error(f"Error al calcular la correlaci√≥n: {e}")
            messagebox.showerror("Error", f"Ocurri√≥ un error al calcular la correlaci√≥n: {e}")

    @staticmethod
    def get_correlation_suggestion(correlacion):
        """Devuelve una sugerencia basada en el valor de la correlaci√≥n."""
        if correlacion >= 0.7:
            return ("Correlaci√≥n alta positiva. Esto significa que cuando se siembra m√°s superficie, "
                    "generalmente se cosecha m√°s. Sugerencia: Mantener pr√°cticas actuales y explorar "
                    "variedades de cultivos de alto rendimiento para maximizar la producci√≥n por hect√°rea.")
        elif correlacion <= 0.3:
            return ("Correlaci√≥n baja. Esto indica que factores externos (clima, plagas, suelo) "
                    "pueden estar causando p√©rdidas entre siembra y cosecha. Sugerencia: Revisar "
                    "pr√°cticas de cultivo, mejorar manejo de factores ambientales y considerar "
                    "t√©cnicas de conservaci√≥n.")
        else:
            return ("Correlaci√≥n moderada. La relaci√≥n entre siembra y cosecha es variable. "
                    "Sugerencia: Considerar diversificaci√≥n de cultivos para reducir riesgos "
                    "y mejorar la estabilidad de la producci√≥n.")

    def produccion_total_por_provincia(self):
        """Genera una gr√°fica de la producci√≥n total por provincia."""
        if not self._check_csv_loaded():
            return
        if 'provincia' not in self.df.columns or 'produccion' not in self.df.columns or 'campa√±a' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'provincia', 'produccion' y 'campa√±a'.")
            return

        # Convertir la columna campa√±a a string para evitar errores
        self.df['campa√±a'] = self.df['campa√±a'].astype(str)
        
        campa√±as = self.df['campa√±a'].unique()
        if len(campa√±as) == 0:
            messagebox.showwarning("Advertencia", "No se encontraron campa√±as en el archivo CSV.")
            return

        campa√±as_limpias = [str(campa√±a).strip() for campa√±a in campa√±as if pd.notna(campa√±a)]

        selected_campa√±a = self.ask_option("Seleccionar Campa√±a", "Seleccione la campa√±a:", campa√±as_limpias)
        if not selected_campa√±a:
            return

        # Filtrar usando comparaci√≥n directa en lugar de .str.strip()
        df_campa√±a = self.df[self.df['campa√±a'].astype(str).str.strip() == selected_campa√±a]
        
        if df_campa√±a.empty:
            messagebox.showwarning("Advertencia", "No se encontraron datos para la campa√±a seleccionada.")
            return
            
        produccion_por_provincia = df_campa√±a.groupby('provincia')['produccion'].sum().sort_values(ascending=False)

        if produccion_por_provincia.empty:
            messagebox.showwarning("Advertencia", "No se encontraron datos de producci√≥n para la campa√±a seleccionada.")
            return

        title = f"Producci√≥n Total por Provincia - Campa√±a {selected_campa√±a}"
        output_file = OUTPUT_DIR / f"produccion_por_provincia_{self.safe_file_name(selected_campa√±a)}.png"
        Visualization.plot_bar_chart(produccion_por_provincia, title, "Provincias", "Producci√≥n [Tn]", output_file, "produccion_total_por_provincia")

        explanation = (
            "üìä PRODUCCI√ìN POR PROVINCIA\n\n"
            "Esta gr√°fica muestra cu√°nto produce cada provincia en la campa√±a seleccionada.\n\n"
            "üîç ¬øQU√â VER?\n"
            "   ‚Ä¢ Provincias con barras m√°s altas = m√°s producci√≥n\n"
            "   ‚Ä¢ Provincias con barras m√°s bajas = menos producci√≥n\n\n"
            "üí° ¬øPARA QU√â SIRVE?\n"
            "   ‚Ä¢ Saber d√≥nde se produce m√°s\n"
            "   ‚Ä¢ Decidir d√≥nde invertir recursos\n"
            "   ‚Ä¢ Planificar distribuci√≥n de ayuda agr√≠cola"
        )
        messagebox.showinfo("Producci√≥n Total por Provincia", f"Gr√°fica guardada en {output_file}\n\n{explanation}")

    def evolucion_cultivos_por_campa√±a(self):
        """Genera un gr√°fico de la evoluci√≥n de los cultivos por campa√±a con nombres limpios y legibles."""
        if not self._check_csv_loaded():
            return
        if 'campa√±a' not in self.df.columns or 'cultivo' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'campa√±a' y 'cultivo'.")
            return

        # Limpiar nombres de cultivos sin normalizar (mantener nombres originales legibles)
        df_trabajo = self.df.copy()
        df_trabajo['cultivo'] = df_trabajo['cultivo'].astype(str).str.strip().str.title()
        
        # Verificar columnas de inter√©s
        columnas_interes = ['sup_sembrada', 'sup_cosechada', 'produccion']
        columnas_presentes = [col for col in columnas_interes if col in df_trabajo.columns]
        if not columnas_presentes:
            messagebox.showwarning("Advertencia", f"El archivo CSV debe contener al menos una de las columnas: {', '.join(columnas_interes)}.")
            return

        # Procesar fechas de campa√±a de manera m√°s robusta
        try:
            # Intentar diferentes formatos de fecha
            if df_trabajo['campa√±a'].dtype == 'object':
                # Si es texto, intentar extraer el a√±o
                df_trabajo['a√±o'] = df_trabajo['campa√±a'].astype(str).str.extract(r'(\d{4})').astype(float)
            else:
                # Si es num√©rico, usar directamente
                df_trabajo['a√±o'] = pd.to_numeric(df_trabajo['campa√±a'], errors='coerce')
            
            # Filtrar a√±os v√°lidos
            df_trabajo = df_trabajo.dropna(subset=['a√±o'])
            df_trabajo['a√±o'] = df_trabajo['a√±o'].astype(int)
            
        except Exception as e:
            logging.error(f"Error procesando fechas de campa√±a: {e}")
            messagebox.showerror("Error", "No se pudieron procesar las fechas de campa√±a correctamente.")
            return

        if df_trabajo.empty:
            messagebox.showwarning("Advertencia", "No se encontraron datos v√°lidos despu√©s del procesamiento.")
            return

        # Obtener cultivos √∫nicos y limpios
        cultivos_disponibles = sorted(df_trabajo['cultivo'].dropna().unique())
        
        if len(cultivos_disponibles) == 0:
            messagebox.showwarning("Advertencia", "No se encontraron cultivos v√°lidos en los datos.")
            return

        # Seleccionar cultivo
        cultivo_seleccionado = self.ask_option("Seleccionar Cultivo", "Seleccione el cultivo:", cultivos_disponibles)
        if not cultivo_seleccionado:
            return

        # Filtrar datos para el cultivo seleccionado
        df_filtrado = df_trabajo[df_trabajo['cultivo'] == cultivo_seleccionado]
        if df_filtrado.empty:
            messagebox.showwarning("Advertencia", f"No se encontraron datos para el cultivo seleccionado: {cultivo_seleccionado}.")
            return

        # Crear visualizaci√≥n mejorada
        plt.figure(figsize=(14, 10))
        
        # Agrupar por a√±o y sumar valores
        datos_agrupados = df_filtrado.groupby('a√±o')[columnas_presentes].sum()
        
        if datos_agrupados.empty:
            messagebox.showwarning("Advertencia", "No hay datos suficientes para generar el gr√°fico.")
            return

        # Crear subgr√°ficos si hay m√∫ltiples columnas
        if len(columnas_presentes) > 1:
            fig, axes = plt.subplots(len(columnas_presentes), 1, figsize=(14, 4*len(columnas_presentes)))
            if len(columnas_presentes) == 1:
                axes = [axes]
            
            for i, columna in enumerate(columnas_presentes):
                axes[i].plot(datos_agrupados.index, datos_agrupados[columna],
                           marker='o', linewidth=2, markersize=6, label=columna)
                axes[i].set_title(f'Evoluci√≥n de {columna.replace("_", " ").title()} - {cultivo_seleccionado}')
                axes[i].set_xlabel('A√±o')
                axes[i].set_ylabel(columna.replace("_", " ").title())
                axes[i].grid(True, alpha=0.3)
                axes[i].legend()
                
                # Agregar valores en los puntos
                for x, y in zip(datos_agrupados.index, datos_agrupados[columna]):
                    axes[i].annotate(f'{y:,.0f}', (x, y), textcoords="offset points",
                                   xytext=(0,10), ha='center', fontsize=8)
        else:
            # Un solo gr√°fico si hay una sola columna
            columna = columnas_presentes[0]
            plt.plot(datos_agrupados.index, datos_agrupados[columna],
                    marker='o', linewidth=3, markersize=8, color='steelblue')
            plt.title(f'Evoluci√≥n de {columna.replace("_", " ").title()} - {cultivo_seleccionado}', fontsize=14)
            plt.xlabel('A√±o', fontsize=12)
            plt.ylabel(columna.replace("_", " ").title(), fontsize=12)
            plt.grid(True, alpha=0.3)
            
            # Agregar valores en los puntos
            for x, y in zip(datos_agrupados.index, datos_agrupados[columna]):
                plt.annotate(f'{y:,.0f}', (x, y), textcoords="offset points",
                           xytext=(0,10), ha='center', fontsize=10, fontweight='bold')

        plt.suptitle("evolucion_cultivos_por_campa√±a", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()

        # Crear nombre de archivo seguro
        cultivo_filename = re.sub(r'[^\w\s-]', '', cultivo_seleccionado).strip().replace(' ', '_')
        evolucion_file = OUTPUT_DIR / f"evolucion_cultivo_{cultivo_filename}.png"
        plt.savefig(evolucion_file, dpi=300, bbox_inches='tight')
        plt.show()
        logging.info(f"Gr√°fica de evoluci√≥n de cultivo guardada en {evolucion_file}")

        # An√°lisis adicional
        a√±os_analizados = len(datos_agrupados)
        a√±o_inicial = datos_agrupados.index.min()
        a√±o_final = datos_agrupados.index.max()
        
        # Calcular tendencias
        tendencias = {}
        for columna in columnas_presentes:
            if len(datos_agrupados) > 1:
                valor_inicial = datos_agrupados[columna].iloc[0]
                valor_final = datos_agrupados[columna].iloc[-1]
                if valor_inicial > 0:
                    cambio_porcentual = ((valor_final - valor_inicial) / valor_inicial) * 100
                    tendencias[columna] = cambio_porcentual
                else:
                    tendencias[columna] = 0

        tendencias_texto = ""
        for columna, cambio in tendencias.items():
            direccion = "üìà Crecimiento" if cambio > 5 else "üìâ Declive" if cambio < -5 else "‚û°Ô∏è Estable"
            tendencias_texto += f"   ‚Ä¢ {columna.replace('_', ' ').title()}: {direccion} ({cambio:+.1f}%)\n"

        explanation = (
            f"üìà EVOLUCI√ìN DEL CULTIVO: {cultivo_seleccionado.upper()}\n\n"
            f"üìÖ A√±os estudiados: {a√±o_inicial} - {a√±o_final}\n"
            f"üìä Variables mostradas: {', '.join([col.replace('_', ' ').title() for col in columnas_presentes])}\n\n"
            f"üìà TENDENCIAS:\n{tendencias_texto}\n"
            f"üí° ¬øQU√â MUESTRA?\n"
            f"   ‚Ä¢ C√≥mo ha cambiado este cultivo a lo largo del tiempo\n"
            f"   ‚Ä¢ Si est√° creciendo, bajando o se mantiene igual\n"
            f"   ‚Ä¢ Los n√∫meros exactos por cada a√±o\n\n"
            f"üìã PARA QU√â SIRVE:\n"
            f"   ‚Ä¢ Saber si vale la pena seguir sembrando este cultivo\n"
            f"   ‚Ä¢ Planificar siembras basadas en el pasado\n"
            f"   ‚Ä¢ Ver el impacto de clima o econom√≠a"
        )
        
        messagebox.showinfo("Evoluci√≥n de Cultivo por Campa√±a", f"Gr√°fica guardada en {evolucion_file}\n\n{explanation}")

    def tendencias_produccion_por_cultivo(self):
        """Genera un gr√°fico de tendencias de producci√≥n por cultivo y campa√±a mejorado."""
        if not self._check_csv_loaded():
            return
        if 'campa√±a' not in self.df.columns or 'cultivo' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'campa√±a', 'cultivo' y 'produccion'.")
            return

        # Filtrar datos v√°lidos
        df_valid = self.df.dropna(subset=['campa√±a', 'cultivo', 'produccion']).copy()
        
        if len(df_valid) < 10:
            messagebox.showwarning("Advertencia", "No hay suficientes datos v√°lidos para el an√°lisis de tendencias.")
            return

        # Agrupar por cultivo y campa√±a, sumando la producci√≥n
        df_grouped = df_valid.groupby(['cultivo', 'campa√±a'])['produccion'].sum().reset_index()
        
        # Obtener los cultivos con mayor producci√≥n total para evitar amontonamiento
        produccion_total_por_cultivo = df_grouped.groupby('cultivo')['produccion'].sum().sort_values(ascending=False)
        
        # Seleccionar solo los top 8 cultivos para mejor visualizaci√≥n
        top_cultivos = produccion_total_por_cultivo.head(8).index.tolist()
        df_top = df_grouped[df_grouped['cultivo'].isin(top_cultivos)]
        
        # Crear subgr√°ficos para mejor visualizaci√≥n
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # Gr√°fico 1: Tendencias de los top 4 cultivos
        top_4_cultivos = top_cultivos[:4]
        for cultivo in top_4_cultivos:
            cultivo_data = df_top[df_top['cultivo'] == cultivo]
            ax1.plot(cultivo_data['campa√±a'], cultivo_data['produccion'],
                    marker='o', linewidth=2, label=cultivo)
        
        ax1.set_title('Tendencias - Top 4 Cultivos por Producci√≥n')
        ax1.set_xlabel('Campa√±a')
        ax1.set_ylabel('Producci√≥n (toneladas)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.tick_params(axis='x', rotation=45)
        
        # Gr√°fico 2: Tendencias de los siguientes 4 cultivos
        if len(top_cultivos) > 4:
            next_4_cultivos = top_cultivos[4:8]
            for cultivo in next_4_cultivos:
                cultivo_data = df_top[df_top['cultivo'] == cultivo]
                ax2.plot(cultivo_data['campa√±a'], cultivo_data['produccion'],
                        marker='s', linewidth=2, label=cultivo)
            
            ax2.set_title('Tendencias - Siguientes 4 Cultivos')
            ax2.set_xlabel('Campa√±a')
            ax2.set_ylabel('Producci√≥n (toneladas)')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            ax2.tick_params(axis='x', rotation=45)
        else:
            ax2.text(0.5, 0.5, 'Menos de 8 cultivos\ndisponibles',
                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)
            ax2.set_title('Cultivos Adicionales')
        
        # Gr√°fico 3: Comparaci√≥n de producci√≥n total por cultivo (barras)
        produccion_total_top = produccion_total_por_cultivo.head(10)
        bars = ax3.bar(range(len(produccion_total_top)), produccion_total_top.values,
                      color='lightblue', edgecolor='navy')
        ax3.set_title('Producci√≥n Total por Cultivo (Top 10)')
        ax3.set_xlabel('Cultivos')
        ax3.set_ylabel('Producci√≥n Total (toneladas)')
        ax3.set_xticks(range(len(produccion_total_top)))
        ax3.set_xticklabels(produccion_total_top.index, rotation=45, ha='right')
        
        # Agregar valores en las barras
        for bar, valor in zip(bars, produccion_total_top.values):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + valor*0.01,
                    f'{valor:,.0f}', ha='center', va='bottom', fontsize=8)
        
        # Gr√°fico 4: Evoluci√≥n promedio de todos los cultivos
        evolucion_promedio = df_grouped.groupby('campa√±a')['produccion'].mean()
        ax4.plot(evolucion_promedio.index, evolucion_promedio.values,
                marker='o', linewidth=3, color='red', label='Promedio General')
        ax4.fill_between(evolucion_promedio.index, evolucion_promedio.values, alpha=0.3, color='red')
        ax4.set_title('Evoluci√≥n Promedio de Producci√≥n')
        ax4.set_xlabel('Campa√±a')
        ax4.set_ylabel('Producci√≥n Promedio (toneladas)')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        ax4.tick_params(axis='x', rotation=45)
        
        plt.suptitle("tendencias_produccion_por_cultivo", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()

        tendencias_file = OUTPUT_DIR / "tendencias_produccion.png"
        plt.savefig(tendencias_file, dpi=300, bbox_inches='tight')
        plt.show()
        logging.info(f"Gr√°fica de tendencias de producci√≥n guardada en {tendencias_file}")

        # An√°lisis adicional
        cultivo_mas_estable = None
        cultivo_mas_variable = None
        
        if len(df_top) > 0:
            # Calcular variabilidad (coeficiente de variaci√≥n) para cada cultivo
            variabilidad_cultivos = {}
            for cultivo in top_cultivos:
                cultivo_data = df_top[df_top['cultivo'] == cultivo]['produccion']
                if len(cultivo_data) > 1:
                    cv = (cultivo_data.std() / cultivo_data.mean()) * 100
                    variabilidad_cultivos[cultivo] = cv
            
            if variabilidad_cultivos:
                cultivo_mas_estable = min(variabilidad_cultivos, key=variabilidad_cultivos.get)
                cultivo_mas_variable = max(variabilidad_cultivos, key=variabilidad_cultivos.get)

        explanation = (
            f"üåæ TENDENCIAS DE PRODUCCI√ìN POR CULTIVO\n\n"
            f"üìä Datos revisados: {len(df_valid):,} registros\n"
            f"üå± Tipos de cultivos: {len(df_valid['cultivo'].unique())}\n\n"
            f"üèÜ CULTIVOS M√ÅS PRODUCTIVOS:\n"
            f"   1. {produccion_total_por_cultivo.index[0]}: {produccion_total_por_cultivo.iloc[0]:,.0f} ton\n"
            f"   2. {produccion_total_por_cultivo.index[1]}: {produccion_total_por_cultivo.iloc[1]:,.0f} ton\n"
            f"   3. {produccion_total_por_cultivo.index[2]}: {produccion_total_por_cultivo.iloc[2]:,.0f} ton\n\n"
            f"üìà ESTABILIDAD:\n"
            f"   üü¢ M√°s estable: {cultivo_mas_estable if cultivo_mas_estable else 'No disponible'}\n"
            f"   üî¥ M√°s variable: {cultivo_mas_variable if cultivo_mas_variable else 'No disponible'}\n\n"
            f"üí° ¬øQU√â MUESTRAN LOS GR√ÅFICOS?\n"
            f"   ‚Ä¢ C√≥mo cambia la producci√≥n de cada cultivo con el tiempo\n"
            f"   ‚Ä¢ Cu√°les cultivos producen m√°s\n"
            f"   ‚Ä¢ Cu√°les son predecibles y cu√°les cambian mucho\n\n"
            f"üìã USO PR√ÅCTICO:\n"
            f"   ‚Ä¢ Elegir cultivos confiables para sembrar\n"
            f"   ‚Ä¢ Diversificar para reducir riesgos\n"
            f"   ‚Ä¢ Planificar inversiones agr√≠colas"
        )
        
        messagebox.showinfo("Tendencias de Producci√≥n por Cultivo", f"Gr√°fica guardada en {tendencias_file}\n\n{explanation}")

    def modelos_predictivos(self):
        """Entrena y eval√∫a un modelo de regresi√≥n lineal."""
        if not self._check_csv_loaded():
            return
        if 'sup_sembrada' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener 'sup_sembrada' y 'produccion'.")
            return

        # Limpiar datos eliminando filas con NaN en las columnas relevantes
        self.df = self.df.dropna(subset=['sup_sembrada', 'produccion'])

        X = self.df[['sup_sembrada']].values
        y = self.df['produccion'].values

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        model = LinearRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        explanation = (
            f"üìà MODELO PREDICTIVO SIMPLE\n\n"
            f"Este an√°lisis usa un modelo matem√°tico simple para predecir la producci√≥n agr√≠cola "
            f"bas√°ndose en la superficie sembrada.\n\n"
            f"üîç RESULTADOS:\n"
            f"   ‚Ä¢ Error promedio del modelo: {mse:.0f} (m√°s bajo es mejor)\n"
            f"   ‚Ä¢ Precisi√≥n del modelo: {r2:.2f} (m√°s cerca de 1 es mejor)\n\n"
            f"üí° ¬øQU√â SIGNIFICA?\n"
            f"   ‚Ä¢ Si el error es bajo y la precisi√≥n alta, el modelo predice bien\n"
            f"   ‚Ä¢ Si no, puede que necesites m√°s datos o variables diferentes\n\n"
            f"üìã USO: Ayuda a estimar producci√≥n futura basada en superficie sembrada"
        )
        messagebox.showinfo("Modelo Predictivo", explanation)

    def clasificacion_cultivos(self):
        """Analiza y clasifica cultivos seg√∫n caracter√≠sticas de producci√≥n."""
        columnas_requeridas = ['cultivo']
        columnas_opcionales = ['sup_sembrada', 'sup_cosechada', 'produccion', 'rendimiento', 'provincia']
        
        if not self._check_csv_loaded():
            return
        if 'cultivo' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener la columna 'cultivo'.")
            return

        # Filtrar datos v√°lidos
        df_valid = self.df.dropna(subset=['cultivo']).copy()
        
        if len(df_valid) < 10:
            messagebox.showwarning("Advertencia", "No hay suficientes datos v√°lidos para realizar la clasificaci√≥n.")
            return

        # An√°lisis descriptivo de cultivos
        total_cultivos = len(df_valid['cultivo'].unique())
        cultivos_mas_comunes = df_valid['cultivo'].value_counts().head(10)
        
        # Crear visualizaci√≥n
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # Gr√°fico 1: Distribuci√≥n de cultivos (top 10)
        cultivos_mas_comunes.plot(kind='bar', ax=ax1, color='lightgreen')
        ax1.set_title('Top 10 Cultivos M√°s Frecuentes')
        ax1.set_xlabel('Tipo de Cultivo')
        ax1.set_ylabel('Cantidad de Registros')
        ax1.tick_params(axis='x', rotation=45)
        
        # Agregar valores en las barras
        for i, v in enumerate(cultivos_mas_comunes.values):
            ax1.text(i, v + 1, str(v), ha='center', va='bottom', fontweight='bold')

        # Gr√°fico 2: Producci√≥n promedio por cultivo (si est√° disponible)
        if 'produccion' in df_valid.columns:
            produccion_por_cultivo = df_valid.groupby('cultivo')['produccion'].mean().sort_values(ascending=False).head(10)
            produccion_por_cultivo.plot(kind='bar', ax=ax2, color='orange')
            ax2.set_title('Producci√≥n Promedio por Cultivo (Top 10)')
            ax2.set_xlabel('Tipo de Cultivo')
            ax2.set_ylabel('Producci√≥n Promedio (toneladas)')
            ax2.tick_params(axis='x', rotation=45)
        else:
            ax2.text(0.5, 0.5, 'Datos de producci√≥n\nno disponibles',
                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)
            ax2.set_title('Producci√≥n por Cultivo')

        # Gr√°fico 3: Superficie sembrada promedio por cultivo (si est√° disponible)
        if 'sup_sembrada' in df_valid.columns:
            superficie_por_cultivo = df_valid.groupby('cultivo')['sup_sembrada'].mean().sort_values(ascending=False).head(10)
            superficie_por_cultivo.plot(kind='bar', ax=ax3, color='skyblue')
            ax3.set_title('Superficie Sembrada Promedio por Cultivo (Top 10)')
            ax3.set_xlabel('Tipo de Cultivo')
            ax3.set_ylabel('Superficie Promedio (hect√°reas)')
            ax3.tick_params(axis='x', rotation=45)
        else:
            ax3.text(0.5, 0.5, 'Datos de superficie\nno disponibles',
                    ha='center', va='center', transform=ax3.transAxes, fontsize=12)
            ax3.set_title('Superficie Sembrada por Cultivo')

        # Gr√°fico 4: Distribuci√≥n por provincia (si est√° disponible)
        if 'provincia' in df_valid.columns:
            cultivos_por_provincia = df_valid.groupby('provincia')['cultivo'].nunique().sort_values(ascending=False).head(10)
            cultivos_por_provincia.plot(kind='bar', ax=ax4, color='lightcoral')
            ax4.set_title('Diversidad de Cultivos por Provincia (Top 10)')
            ax4.set_xlabel('Provincia')
            ax4.set_ylabel('Cantidad de Tipos de Cultivos')
            ax4.tick_params(axis='x', rotation=45)
        else:
            # Gr√°fico de torta de cultivos principales
            cultivos_principales = df_valid['cultivo'].value_counts().head(8)
            otros = df_valid['cultivo'].value_counts().iloc[8:].sum()
            if otros > 0:
                cultivos_principales['Otros'] = otros
            
            ax4.pie(cultivos_principales.values, labels=cultivos_principales.index, autopct='%1.1f%%')
            ax4.set_title('Distribuci√≥n de Cultivos Principales')

        plt.suptitle("clasificacion_cultivos", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()
        
        # Guardar gr√°fico
        clasificacion_file = OUTPUT_DIR / "clasificacion_cultivos.png"
        plt.savefig(clasificacion_file, dpi=300, bbox_inches='tight')
        plt.show()
        logging.info(f"An√°lisis de clasificaci√≥n de cultivos guardado en {clasificacion_file}")

        # Estad√≠sticas adicionales
        estadisticas_adicionales = ""
        if 'produccion' in df_valid.columns:
            cultivo_mas_productivo = df_valid.groupby('cultivo')['produccion'].mean().idxmax()
            produccion_maxima = df_valid.groupby('cultivo')['produccion'].mean().max()
            estadisticas_adicionales += f"\nüèÜ Cultivo m√°s productivo: {cultivo_mas_productivo} ({produccion_maxima:.0f} ton promedio)"
        
        if 'sup_sembrada' in df_valid.columns:
            cultivo_mayor_superficie = df_valid.groupby('cultivo')['sup_sembrada'].mean().idxmax()
            superficie_maxima = df_valid.groupby('cultivo')['sup_sembrada'].mean().max()
            estadisticas_adicionales += f"\nüåæ Cultivo con mayor superficie: {cultivo_mayor_superficie} ({superficie_maxima:.0f} ha promedio)"

        explanation = (
            f"üìä CLASIFICACI√ìN Y AN√ÅLISIS DE CULTIVOS\n\n"
            f"üîç Datos analizados: {len(df_valid):,} registros de cultivos\n"
            f"üå± Total de tipos de cultivos: {total_cultivos}\n\n"
            f"üìà Top 3 Cultivos M√°s Frecuentes:\n"
            f"   1. {cultivos_mas_comunes.index[0]}: {cultivos_mas_comunes.iloc[0]} registros\n"
            f"   2. {cultivos_mas_comunes.index[1]}: {cultivos_mas_comunes.iloc[1]} registros\n"
            f"   3. {cultivos_mas_comunes.index[2]}: {cultivos_mas_comunes.iloc[2]} registros\n"
            f"{estadisticas_adicionales}\n\n"
            f"üí° ¬øQu√© muestra este an√°lisis?\n"
            f"   ‚Ä¢ Identifica qu√© cultivos son m√°s comunes en tu dataset\n"
            f"   ‚Ä¢ Compara la productividad promedio entre diferentes cultivos\n"
            f"   ‚Ä¢ Analiza qu√© cultivos requieren m√°s superficie para sembrar\n"
            f"   ‚Ä¢ Muestra la diversidad de cultivos por regi√≥n\n\n"
            f"üìã Utilidad pr√°ctica:\n"
            f"   ‚Ä¢ Planificaci√≥n de siembra basada en cultivos exitosos\n"
            f"   ‚Ä¢ Identificaci√≥n de oportunidades de diversificaci√≥n\n"
            f"   ‚Ä¢ Comparaci√≥n de eficiencia entre cultivos\n"
            f"   ‚Ä¢ An√°lisis de especializaci√≥n regional"
        )
        
        messagebox.showinfo("Clasificaci√≥n de Cultivos", explanation)

    def analisis_riesgos(self):
        """Realiza un an√°lisis de riesgos agr√≠colas identificando zonas de alta, media y baja producci√≥n por provincia y campa√±a."""
        columnas_requeridas = ['produccion']
        columnas_opcionales = ['provincia', 'campa√±a', 'departamento']
        
        # Verificar columnas requeridas
        if not self._check_csv_loaded():
            return
        if not all(col in self.df.columns for col in columnas_requeridas):
            messagebox.showwarning("Advertencia", "El DataFrame debe contener la columna 'produccion'.")
            return

        # Filtrar filas con datos v√°lidos en 'produccion'
        df_valid = self.df[self.df['produccion'].notna() & (self.df['produccion'] > 0)].copy()

        if len(df_valid) < 10:
            messagebox.showwarning("Advertencia", "No hay suficientes datos v√°lidos para realizar el an√°lisis de riesgos.")
            return

        # Limitar a una muestra para evitar consumo excesivo de RAM
        if len(df_valid) > 5000:
            df_valid = df_valid.sample(n=5000, random_state=42)
            logging.info("Muestra limitada a 5000 filas para an√°lisis de riesgos.")

        # Obtener informaci√≥n temporal si est√° disponible
        campa√±as_info = ""
        if 'campa√±a' in df_valid.columns:
            campa√±as_unicas = sorted(df_valid['campa√±a'].dropna().unique())
            if len(campa√±as_unicas) > 0:
                primera_campa√±a = campa√±as_unicas[0]
                ultima_campa√±a = campa√±as_unicas[-1]
                total_campa√±as = len(campa√±as_unicas)
                campa√±as_info = f"üìÖ Per√≠odo analizado: {primera_campa√±a} - {ultima_campa√±a} ({total_campa√±as} campa√±as)\n"

        # Calcular estad√≠sticas b√°sicas de producci√≥n
        produccion_values = df_valid['produccion'].values
        media_produccion = np.mean(produccion_values)
        std_produccion = np.std(produccion_values)
        min_produccion = np.min(produccion_values)
        max_produccion = np.max(produccion_values)

        # Definir umbrales de riesgo basados en percentiles
        percentil_33 = np.percentile(produccion_values, 33)
        percentil_66 = np.percentile(produccion_values, 66)

        # Clasificar riesgos
        def clasificar_riesgo(produccion):
            if produccion <= percentil_33:
                return 'Alto Riesgo'
            elif produccion <= percentil_66:
                return 'Riesgo Medio'
            else:
                return 'Bajo Riesgo'

        # Aplicar clasificaci√≥n
        df_valid['Nivel_Riesgo'] = df_valid['produccion'].apply(clasificar_riesgo)
        
        # Contar casos por nivel de riesgo
        conteo_riesgos = df_valid['Nivel_Riesgo'].value_counts()

        # An√°lisis por provincia si est√° disponible
        zonas_alto_riesgo = []
        zonas_medio_riesgo = []
        zonas_bajo_riesgo = []
        
        if 'provincia' in df_valid.columns:
            # Agrupar por provincia y calcular producci√≥n promedio
            produccion_por_provincia = df_valid.groupby('provincia').agg({
                'produccion': ['mean', 'count'],
                'Nivel_Riesgo': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Sin datos'
            }).round(2)
            
            produccion_por_provincia.columns = ['Produccion_Promedio', 'Cantidad_Registros', 'Nivel_Riesgo_Predominante']
            produccion_por_provincia = produccion_por_provincia.reset_index()
            
            # Clasificar provincias por nivel de riesgo predominante
            for _, row in produccion_por_provincia.iterrows():
                provincia = row['provincia']
                nivel = row['Nivel_Riesgo_Predominante']
                prod_prom = row['Produccion_Promedio']
                
                if nivel == 'Alto Riesgo':
                    zonas_alto_riesgo.append(f"{provincia} ({prod_prom:.0f} ton promedio)")
                elif nivel == 'Riesgo Medio':
                    zonas_medio_riesgo.append(f"{provincia} ({prod_prom:.0f} ton promedio)")
                else:
                    zonas_bajo_riesgo.append(f"{provincia} ({prod_prom:.0f} ton promedio)")

        # Crear visualizaci√≥n mejorada
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # Gr√°fico 1: Histograma de producci√≥n con umbrales de riesgo
        ax1.hist(produccion_values, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        ax1.axvline(percentil_33, color='red', linestyle='--', linewidth=2, label=f'Alto Riesgo (‚â§{percentil_33:.0f})')
        ax1.axvline(percentil_66, color='orange', linestyle='--', linewidth=2, label=f'Riesgo Medio (‚â§{percentil_66:.0f})')
        ax1.axvline(media_produccion, color='green', linestyle='-', linewidth=2, label=f'Media ({media_produccion:.0f})')
        ax1.set_xlabel('Producci√≥n (toneladas)')
        ax1.set_ylabel('Frecuencia')
        ax1.set_title('Distribuci√≥n de Producci√≥n con Umbrales de Riesgo')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # Gr√°fico 2: Gr√°fico de barras por nivel de riesgo
        colores = ['red', 'orange', 'green']
        bars = ax2.bar(conteo_riesgos.index, conteo_riesgos.values, color=colores)
        ax2.set_xlabel('Nivel de Riesgo')
        ax2.set_ylabel('Cantidad de Casos')
        ax2.set_title('Distribuci√≥n por Nivel de Riesgo')
        
        # Agregar valores en las barras
        for bar, valor in zip(bars, conteo_riesgos.values):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    str(valor), ha='center', va='bottom', fontweight='bold')

        # Gr√°fico 3: Producci√≥n por provincia si est√° disponible
        if 'provincia' in df_valid.columns and len(produccion_por_provincia) <= 15:
            produccion_por_provincia_sorted = produccion_por_provincia.sort_values('Produccion_Promedio')
            colores_provincias = ['red' if x == 'Alto Riesgo' else 'orange' if x == 'Riesgo Medio' else 'green'
                                for x in produccion_por_provincia_sorted['Nivel_Riesgo_Predominante']]
            
            bars = ax3.barh(produccion_por_provincia_sorted['provincia'],
                           produccion_por_provincia_sorted['Produccion_Promedio'],
                           color=colores_provincias)
            ax3.set_xlabel('Producci√≥n Promedio (toneladas)')
            ax3.set_ylabel('Provincia')
            ax3.set_title('Producci√≥n Promedio por Provincia')
            ax3.grid(True, alpha=0.3)
        else:
            # Gr√°fico de dispersi√≥n alternativo
            colores_scatter = {'Alto Riesgo': 'red', 'Riesgo Medio': 'orange', 'Bajo Riesgo': 'green'}
            for nivel in df_valid['Nivel_Riesgo'].unique():
                subset = df_valid[df_valid['Nivel_Riesgo'] == nivel]
                ax3.scatter(range(len(subset)), subset['produccion'],
                           c=colores_scatter[nivel], label=nivel, alpha=0.6)
            ax3.set_xlabel('√çndice de Registro')
            ax3.set_ylabel('Producci√≥n (toneladas)')
            ax3.set_title('Producci√≥n por Registro Clasificada por Riesgo')
            ax3.legend()
            ax3.grid(True, alpha=0.3)

        # Gr√°fico 4: Gr√°fico de torta
        ax4.pie(conteo_riesgos.values, labels=conteo_riesgos.index, colors=colores,
                autopct='%1.1f%%', startangle=90)
        ax4.set_title('Proporci√≥n de Niveles de Riesgo')

        plt.suptitle("analisis_riesgos", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()
        
        # Guardar gr√°fico
        riesgo_file = OUTPUT_DIR / "analisis_riesgos_agricola.png"
        plt.savefig(riesgo_file, dpi=300, bbox_inches='tight')
        plt.show()
        logging.info(f"An√°lisis de riesgos guardado en {riesgo_file}")

        # Asignar clasificaci√≥n al DataFrame principal
        self.df.loc[df_valid.index, 'Nivel_Riesgo'] = df_valid['Nivel_Riesgo']

        # Crear reporte detallado
        porcentaje_alto = (conteo_riesgos.get('Alto Riesgo', 0) / len(df_valid)) * 100
        porcentaje_medio = (conteo_riesgos.get('Riesgo Medio', 0) / len(df_valid)) * 100
        porcentaje_bajo = (conteo_riesgos.get('Bajo Riesgo', 0) / len(df_valid)) * 100

        # Construir informaci√≥n de zonas
        zonas_info = ""
        if zonas_alto_riesgo or zonas_medio_riesgo or zonas_bajo_riesgo:
            zonas_info += "\nüó∫Ô∏è ZONAS IDENTIFICADAS:\n"
            if zonas_alto_riesgo:
                zonas_info += f"   üî¥ ALTO RIESGO: {', '.join(zonas_alto_riesgo[:5])}"
                if len(zonas_alto_riesgo) > 5:
                    zonas_info += f" y {len(zonas_alto_riesgo)-5} m√°s"
                zonas_info += "\n"
            if zonas_medio_riesgo:
                zonas_info += f"   üü° RIESGO MEDIO: {', '.join(zonas_medio_riesgo[:5])}"
                if len(zonas_medio_riesgo) > 5:
                    zonas_info += f" y {len(zonas_medio_riesgo)-5} m√°s"
                zonas_info += "\n"
            if zonas_bajo_riesgo:
                zonas_info += f"   üü¢ BAJO RIESGO: {', '.join(zonas_bajo_riesgo[:5])}"
                if len(zonas_bajo_riesgo) > 5:
                    zonas_info += f" y {len(zonas_bajo_riesgo)-5} m√°s"
                zonas_info += "\n"

        explanation = (
            f"üìä AN√ÅLISIS DE RIESGOS AGR√çCOLAS\n\n"
            f"{campa√±as_info}"
            f"üîç Datos analizados: {len(df_valid):,} registros de producci√≥n\n\n"
            f"üìà Estad√≠sticas de Producci√≥n:\n"
            f"   ‚Ä¢ Producci√≥n m√≠nima: {min_produccion:,.0f} toneladas\n"
            f"   ‚Ä¢ Producci√≥n m√°xima: {max_produccion:,.0f} toneladas\n"
            f"   ‚Ä¢ Producci√≥n promedio: {media_produccion:,.0f} toneladas\n\n"
            f"‚ö†Ô∏è Clasificaci√≥n de Riesgos:\n"
            f"   üî¥ ALTO RIESGO (‚â§{percentil_33:.0f} ton): {conteo_riesgos.get('Alto Riesgo', 0)} casos ({porcentaje_alto:.1f}%)\n"
            f"   üü° RIESGO MEDIO ({percentil_33:.0f}-{percentil_66:.0f} ton): {conteo_riesgos.get('Riesgo Medio', 0)} casos ({porcentaje_medio:.1f}%)\n"
            f"   üü¢ BAJO RIESGO (>{percentil_66:.0f} ton): {conteo_riesgos.get('Bajo Riesgo', 0)} casos ({porcentaje_bajo:.1f}%)\n"
            f"{zonas_info}\n"
            f"üí° Interpretaci√≥n:\n"
            f"   ‚Ä¢ Las zonas de ALTO RIESGO requieren atenci√≥n inmediata\n"
            f"   ‚Ä¢ Las zonas de RIESGO MEDIO necesitan monitoreo\n"
            f"   ‚Ä¢ Las zonas de BAJO RIESGO son las m√°s productivas\n\n"
            f"üìã Recomendaciones:\n"
            f"   ‚Ä¢ Investigar causas en zonas de alto riesgo (clima, suelo, plagas)\n"
            f"   ‚Ä¢ Implementar mejores pr√°cticas en zonas de riesgo medio\n"
            f"   ‚Ä¢ Replicar estrategias exitosas de zonas de bajo riesgo"
        )
        
        messagebox.showinfo("An√°lisis de Riesgos Agr√≠colas", explanation)


    def prediccion_tendencias_ia(self):
        """Realiza predicci√≥n avanzada de tendencias agr√≠colas usando m√∫ltiples algoritmos de IA con optimizaci√≥n de hiperpar√°metros."""
        if not self._check_csv_loaded():
            return
        if 'campa√±a' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener las columnas 'campa√±a' y 'produccion'.")
            return

        # Preparar datos
        df_trabajo = self.df.dropna(subset=['campa√±a', 'produccion']).copy()
        if len(df_trabajo) < 10:
            messagebox.showwarning("Advertencia", "Se necesitan al menos 10 registros para el an√°lisis predictivo.")
            return

        # Convertir campa√±a a valores num√©ricos para el an√°lisis (manejar formato "2023/2024")
        try:
            # Intentar convertir campa√±as al formato usado en otras funciones
            df_trabajo['a√±o_numerico'] = df_trabajo['campa√±a'].astype(str).str.split('/').str[0].astype(int)
        except (ValueError, AttributeError):
            # Si no funciona, intentar conversi√≥n directa
            df_trabajo['a√±o_numerico'] = pd.to_numeric(df_trabajo['campa√±a'], errors='coerce')

        # Filtrar valores v√°lidos
        df_trabajo = df_trabajo.dropna(subset=['a√±o_numerico'])
        if len(df_trabajo) < 10:
            messagebox.showwarning("Advertencia", "No hay suficientes datos v√°lidos despu√©s del procesamiento de las campa√±as.")
            return
        df_trabajo['a√±o_numerico'] = df_trabajo['a√±o_numerico'].astype(int)

        # Limitar el tama√±o del dataset para evitar tiempos de procesamiento excesivos
        max_samples = 1000
        if len(df_trabajo) > max_samples:
            df_trabajo = df_trabajo.sample(n=max_samples, random_state=42)
            logging.info(f"Dataset limitado a {max_samples} muestras para optimizaci√≥n de rendimiento.")

        X = df_trabajo[['a√±o_numerico']].values
        y = df_trabajo['produccion'].values

        # Escalar caracter√≠sticas para mejor rendimiento
        scaler_X = StandardScaler()
        scaler_y = StandardScaler()

        X_scaled = scaler_X.fit_transform(X)
        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()

        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)
        X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.2, random_state=42)

        # Definir modelos y par√°metros para comparaci√≥n (optimizado para velocidad)
        models = {
            'SVR RBF': {
                'model': SVR(),
                'params': {
                    'kernel': ['rbf'],
                    'C': [1, 10],  # Reducido
                    'gamma': ['scale', 0.1],  # Reducido
                    'epsilon': [0.1]  # Reducido
                }
            },
            'Random Forest': {
                'model': RandomForestRegressor(random_state=42),
                'params': {
                    'n_estimators': [50, 100],  # Reducido
                    'max_depth': [None, 10],  # Reducido
                    'min_samples_split': [2, 5]  # Reducido
                }
            }
        }

        # Entrenar y evaluar modelos
        results = {}
        best_model = None
        best_score = -float('inf')
        best_model_name = ""

        print("üîç Optimizando modelos de IA...")

        for name, config in models.items():
            try:
                # Grid Search con validaci√≥n cruzada (optimizado)
                grid_search = GridSearchCV(
                    config['model'],
                    config['params'],
                    cv=3,  # Reducido de 5 a 3 para mayor velocidad
                    scoring='neg_mean_squared_error',
                    n_jobs=1,  # Cambiado a 1 para evitar problemas de paralelizaci√≥n
                    verbose=1  # Agregado para mostrar progreso
                )

                grid_search.fit(X_train, y_train)

                # Evaluar en conjunto de prueba
                y_pred_scaled = grid_search.predict(X_test)
                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()

                # Calcular m√©tricas
                mse = mean_squared_error(y_test_orig, y_pred)
                rmse = np.sqrt(mse)
                mae = np.mean(np.abs(y_test_orig - y_pred))
                r2 = r2_score(y_test_orig, y_pred)

                results[name] = {
                    'model': grid_search.best_estimator_,
                    'params': grid_search.best_params_,
                    'mse': mse,
                    'rmse': rmse,
                    'mae': mae,
                    'r2': r2,
                    'y_pred': y_pred,
                    'cv_score': -grid_search.best_score_
                }

                # Actualizar mejor modelo
                if r2 > best_score:
                    best_score = r2
                    best_model = grid_search.best_estimator_
                    best_model_name = name

                print(f"‚úÖ {name}: R¬≤ = {r2:.3f}, RMSE = {rmse:.2f}")

            except Exception as e:
                print(f"‚ùå Error en {name}: {e}")
                continue

        if not results:
            messagebox.showerror("Error", "No se pudieron entrenar los modelos correctamente.")
            return

        # Crear visualizaci√≥n comparativa
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

        # Gr√°fico 1: Comparaci√≥n de modelos
        model_names = list(results.keys())
        r2_scores = [results[name]['r2'] for name in model_names]
        rmse_scores = [results[name]['rmse'] for name in model_names]

        x = np.arange(len(model_names))
        width = 0.35

        bars1 = ax1.bar(x - width/2, r2_scores, width, label='R¬≤', color='skyblue', alpha=0.8)
        ax1.set_ylabel('Coeficiente de Determinaci√≥n (R¬≤)', color='skyblue')
        ax1.set_title('Comparaci√≥n de Rendimiento de Modelos')
        ax1.set_xticks(x)
        ax1.set_xticklabels(model_names, rotation=45)
        ax1.legend(loc='upper left')

        ax1_twin = ax1.twinx()
        bars2 = ax1_twin.bar(x + width/2, rmse_scores, width, label='RMSE', color='orange', alpha=0.8)
        ax1_twin.set_ylabel('Error Cuadr√°tico Medio (RMSE)', color='orange')
        ax1_twin.legend(loc='upper right')

        # Agregar valores en barras
        for bar, val in zip(bars1, r2_scores):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{val:.3f}', ha='center', va='bottom', fontsize=8)

        for bar, val in zip(bars2, rmse_scores):
            ax1_twin.text(bar.get_x() + bar.get_width()/2, bar.get_height() + val*0.02,
                         f'{val:.0f}', ha='center', va='bottom', fontsize=8)

        # Gr√°fico 2: Predicciones vs Valores Reales (mejor modelo)
        best_result = results[best_model_name]
        ax2.scatter(y_test_orig, best_result['y_pred'], alpha=0.6, color='green', s=50)
        ax2.plot([y_test_orig.min(), y_test_orig.max()],
                [y_test_orig.min(), y_test_orig.max()],
                'r--', linewidth=2, label='L√≠nea ideal')
        ax2.set_xlabel('Producci√≥n Real (toneladas)')
        ax2.set_ylabel('Producci√≥n Predicha (toneladas)')
        ax2.set_title(f'Predicciones vs Realidad - {best_model_name}')
        ax2.grid(True, alpha=0.3)
        ax2.legend()

        # Agregar l√≠nea de tendencia
        z = np.polyfit(y_test_orig, best_result['y_pred'], 1)
        p = np.poly1d(z)
        ax2.plot(y_test_orig, p(y_test_orig), "b--", alpha=0.8, label='Tendencia')

        # Gr√°fico 3: Serie temporal con predicciones
        a√±os_ordenados = np.sort(df_trabajo['a√±o_numerico'].unique())
        produccion_real = df_trabajo.groupby('a√±o_numerico')['produccion'].mean()

        ax3.plot(produccion_real.index, produccion_real.values,
                'o-', linewidth=2, label='Producci√≥n Real', color='blue')

        # Generar predicciones para a√±os futuros
        a√±os_futuros = np.arange(a√±os_ordenados.max() + 1, a√±os_ordenados.max() + 6)
        X_futuro = scaler_X.transform(a√±os_futuros.reshape(-1, 1))
        y_futuro_scaled = best_model.predict(X_futuro)
        y_futuro = scaler_y.inverse_transform(y_futuro_scaled.reshape(-1, 1)).ravel()

        ax3.plot(a√±os_futuros, y_futuro, 'r--o', linewidth=2,
                label='Predicci√≥n IA (5 a√±os)', markersize=6)

        ax3.set_xlabel('Campa√±a')
        ax3.set_ylabel('Producci√≥n Promedio (toneladas)')
        ax3.set_title('Tendencias Hist√≥ricas y Predicciones Futuras')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # Gr√°fico 4: Distribuci√≥n de errores
        errores = y_test_orig - best_result['y_pred']
        ax4.hist(errores, bins=20, alpha=0.7, color='purple', edgecolor='black')
        ax4.axvline(0, color='red', linestyle='--', linewidth=2, label='Sin error')
        ax4.set_xlabel('Error de Predicci√≥n (toneladas)')
        ax4.set_ylabel('Frecuencia')
        ax4.set_title('Distribuci√≥n de Errores de Predicci√≥n')
        ax4.legend()
        ax4.grid(True, alpha=0.3)

        # Estad√≠sticas de errores
        error_mean = np.mean(errores)
        error_std = np.std(errores)
        ax4.text(0.02, 0.98, f'Error promedio: {error_mean:.1f} ton\nDesviaci√≥n: {error_std:.1f} ton',
                transform=ax4.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

        plt.suptitle("prediccion_tendencias_ia", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()

        # Guardar gr√°fico
        output_file = OUTPUT_DIR / "prediccion_tendencias_ia_avanzada.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()
        logging.info(f"An√°lisis predictivo avanzado guardado en {output_file}")

        # Crear reporte detallado
        best_result = results[best_model_name]

        # Calcular estad√≠sticas adicionales
        total_datos = len(df_trabajo)
        a√±os_unicos = len(df_trabajo['a√±o_numerico'].unique())
        produccion_total = df_trabajo['produccion'].sum()

        # An√°lisis de tendencias
        a√±os_sorted = sorted(df_trabajo['a√±o_numerico'].unique())
        if len(a√±os_sorted) > 1:
            prod_inicial = df_trabajo[df_trabajo['a√±o_numerico'] == a√±os_sorted[0]]['produccion'].mean()
            prod_final = df_trabajo[df_trabajo['a√±o_numerico'] == a√±os_sorted[-1]]['produccion'].mean()
            if prod_inicial > 0:
                cambio_total = ((prod_final - prod_inicial) / prod_inicial) * 100
            else:
                cambio_total = 0
        else:
            cambio_total = 0

        explanation = (
            f"ü§ñ PREDICCI√ìN DE TENDENCIAS CON IA\n\n"
            f"üìä Datos usados: {total_datos:,} registros de producci√≥n agr√≠cola\n"
            f"üìÖ A√±os analizados: {a√±os_sorted[0]} - {a√±os_sorted[-1]}\n"
            f"üåæ Producci√≥n total hist√≥rica: {produccion_total:,.0f} toneladas\n\n"
            f"üèÜ MEJOR M√âTODO ENCONTRADO: {best_model_name}\n"
            f"   ‚Ä¢ Precisi√≥n del modelo: {best_result['r2']:.2f} (m√°s cerca de 1 = mejor)\n"
            f"   ‚Ä¢ Error promedio: {best_result['rmse']:.0f} toneladas\n\n"
            f"üîÆ PREDICCIONES PARA LOS PR√ìXIMOS 5 A√ëOS:\n"
            f"   ‚Ä¢ {a√±os_futuros[0]}: {y_futuro[0]:,.0f} toneladas\n"
            f"   ‚Ä¢ {a√±os_futuros[1]}: {y_futuro[1]:,.0f} toneladas\n"
            f"   ‚Ä¢ {a√±os_futuros[2]}: {y_futuro[2]:,.0f} toneladas\n"
            f"   ‚Ä¢ {a√±os_futuros[3]}: {y_futuro[3]:,.0f} toneladas\n"
            f"   ‚Ä¢ {a√±os_futuros[4]}: {y_futuro[4]:,.0f} toneladas\n\n"
            f"üìà TENDENCIA GENERAL:\n"
            f"   ‚Ä¢ Cambio en el per√≠odo estudiado: {cambio_total:+.1f}%\n"
            f"   ‚Ä¢ Direcci√≥n: {'üìà Producci√≥n subiendo' if cambio_total > 5 else 'üìâ Producci√≥n bajando' if cambio_total < -5 else '‚û°Ô∏è Producci√≥n estable'}\n\n"
            f"üí° ¬øQU√â SIGNIFICA ESTO?\n"
            f"   ‚Ä¢ La IA encontr√≥ patrones en tus datos hist√≥ricos\n"
            f"   ‚Ä¢ Las predicciones te ayudan a planificar el futuro\n"
            f"   ‚Ä¢ Si la precisi√≥n es buena, puedes confiar en las estimaciones\n\n"
            f"üìã PARA QU√â USARLO:\n"
            f"   ‚Ä¢ Planificar cu√°nta superficie sembrar\n"
            f"   ‚Ä¢ Decidir inversiones en agricultura\n"
            f"   ‚Ä¢ Prepararte para a√±os buenos o malos"
        )

        messagebox.showinfo("Predicci√≥n Avanzada de Tendencias con IA",
                          f"An√°lisis completado y guardado en {output_file}\n\n{explanation}")

    def analisis_predictivo_nn(self):
        """Realiza un an√°lisis predictivo utilizando una red neuronal simple."""
        if not self._check_csv_loaded():
            return
        if 'sup_sembrada' not in self.df.columns or 'sup_cosechada' not in self.df.columns or 'rendimiento' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener las columnas 'sup_sembrada', 'sup_cosechada', 'rendimiento' y 'produccion'.")
            return

        # Limpiar datos eliminando filas con NaN
        df_clean = self.df.dropna(subset=['sup_sembrada', 'sup_cosechada', 'rendimiento', 'produccion'])
        if len(df_clean) < 10:
            messagebox.showwarning("Advertencia", "No hay suficientes datos v√°lidos despu√©s de eliminar valores NaN.")
            return

        # Preparar datos
        features = df_clean[['sup_sembrada', 'sup_cosechada', 'rendimiento']]
        target = df_clean['produccion']

        # Escalado de caracter√≠sticas con scalers separados
        scaler_features = MinMaxScaler()
        scaler_target = MinMaxScaler()
        features_scaled = scaler_features.fit_transform(features)
        target_scaled = scaler_target.fit_transform(target.values.reshape(-1, 1)).ravel()

        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(features_scaled, target_scaled, test_size=0.2, random_state=42)

        # Construir modelo de red neuronal
        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(3,)),
            tf.keras.layers.Dense(10, activation='relu'),
            tf.keras.layers.Dense(8, activation='relu'),
            tf.keras.layers.Dense(1)
        ])

        # Compilar modelo
        model.compile(optimizer='adam', loss='mean_squared_error')

        # Entrenar modelo
        model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=0)

        # Evaluar modelo
        loss = model.evaluate(X_test, y_test, verbose=0)
        logging.info(f"P√©rdida en el conjunto de prueba: {loss}")

        # Predicciones
        predictions_scaled = model.predict(X_test, verbose=0)
        predictions_rescaled = scaler_target.inverse_transform(predictions_scaled).ravel()

        # Mostrar algunas predicciones
        logging.info(f"Algunas predicciones reescaladas: {predictions_rescaled[:5]}")
        logging.info(f"Valores reales correspondientes: {scaler_target.inverse_transform(y_test.reshape(-1, 1)).ravel()[:5]}")

        # Calcular m√©tricas adicionales
        mse = mean_squared_error(scaler_target.inverse_transform(y_test.reshape(-1, 1)).ravel(), predictions_rescaled)
        r2 = r2_score(scaler_target.inverse_transform(y_test.reshape(-1, 1)).ravel(), predictions_rescaled)

        explanation = (
            f"üß† PREDICCI√ìN CON RED NEURONAL\n\n"
            f"Este an√°lisis usa una 'red neuronal' (como un cerebro artificial) para predecir la producci√≥n agr√≠cola "
            f"usando superficie sembrada, cosechada y rendimiento.\n\n"
            f"üîç RESULTADOS:\n"
            f"   ‚Ä¢ Error del modelo: {mse:.0f} (m√°s bajo = mejor predicci√≥n)\n"
            f"   ‚Ä¢ Precisi√≥n: {r2:.2f} (m√°s cerca de 1 = m√°s preciso)\n\n"
            f"üí° ¬øQU√â ES UNA RED NEURONAL?\n"
            f"   ‚Ä¢ Un sistema de IA que aprende patrones complejos\n"
            f"   ‚Ä¢ √ötil cuando las relaciones no son simples\n\n"
            f"üìã USO: Predecir producci√≥n basada en m√∫ltiples variables"
        )
        messagebox.showinfo("An√°lisis Predictivo con Red Neuronal", explanation)

    def geocodificar_direcciones(self):
        """Geocodifica direcciones con barra de progreso moderna y guarda las coordenadas en el DataFrame."""
        if not self._check_csv_loaded():
            return
        # Los nombres de columnas ya est√°n normalizados a min√∫sculas en cargar_csv()
        if 'departamento' not in self.df.columns or 'provincia' not in self.df.columns or 'pais' not in self.df.columns:
            messagebox.showwarning("Advertencia", "Por favor, aseg√∫rese de que el archivo CSV contenga las columnas 'departamento', 'provincia' y 'pais' (pueden estar en may√∫sculas o con acentos).")
            return

        def geocode_with_retry(address, max_retries=3):
            for attempt in range(max_retries):
                try:
                    # Pausa m√°s larga para respetar los l√≠mites del servicio
                    sleep(2)
                    location = geolocator.geocode(address, timeout=30)
                    return location
                except (GeocoderTimedOut, GeocoderServiceError) as e:
                    logging.warning(f"Error de geocodificaci√≥n en intento {attempt + 1}: {e}")
                    if attempt < max_retries - 1:
                        sleep(10)  # Espera m√°s larga antes de reintentar
                        continue
                    else:
                        logging.error(f"Fall√≥ geocodificaci√≥n despu√©s de {max_retries} intentos para: {address}")
                        return None
                except Exception as e:
                    logging.error(f"Error inesperado en geocodificaci√≥n: {e}")
                    if attempt < max_retries - 1:
                        sleep(20)  # Espera a√∫n m√°s larga para errores de conexi√≥n
                        continue
                    else:
                        return None
            return None

        # Crear ventana de progreso moderna
        progress_window = tk.Toplevel(self.root)
        progress_window.title("üó∫Ô∏è Progreso - Geocodificaci√≥n")
        progress_window.geometry("550x250")
        progress_window.resizable(False, False)
        progress_window.grab_set()  # Hacer la ventana modal
        progress_window.configure(bg='#F8FAFC')

        # Centrar la ventana
        progress_window.transient(self.root)

        # Frame principal
        main_frame = tk.Frame(progress_window, bg='#F8FAFC')
        main_frame.pack(fill=tk.BOTH, expand=True, padx=25, pady=25)

        # T√≠tulo moderno
        title_label = tk.Label(main_frame, text="üó∫Ô∏è Geocodificando Direcciones",
                              font=('Arial', 16, 'bold'), fg='#2563EB', bg='#F8FAFC')
        title_label.pack(pady=(0, 20))

        # Informaci√≥n del progreso
        total_rows = len(self.df)
        info_label = tk.Label(main_frame, text=f"Procesando {total_rows} direcciones...",
                             font=('Arial', 12), fg='#64748B', bg='#F8FAFC')
        info_label.pack(pady=(0, 15))

        # Barra de progreso moderna
        progress_var = tk.DoubleVar()
        progress_bar = ttk.Progressbar(main_frame, variable=progress_var,
                                      maximum=100, length=450, mode='determinate')
        progress_bar.pack(pady=(0, 15))

        # Etiqueta de estado
        status_label = tk.Label(main_frame, text="‚è≥ Iniciando geocodificaci√≥n...",
                               font=('Arial', 11), fg='#06B6D4', bg='#F8FAFC')
        status_label.pack(pady=(0, 10))

        # Etiqueta de progreso num√©rico
        progress_label = tk.Label(main_frame, text="0 / 0 (0%)",
                                 font=('Arial', 10), fg='#64748B', bg='#F8FAFC')
        progress_label.pack()

        latitudes = []
        longitudes = []
        addresses = []
        
        # Actualizar la ventana para mostrarla
        progress_window.update()

        # Usar contador manual para evitar problemas de tipo
        contador = 0
        for index, row in self.df.iterrows():
            contador += 1
            # Actualizar informaci√≥n de progreso
            current_progress = (contador / total_rows) * 100
            progress_var.set(current_progress)
            
            address = f"{row['departamento']}, {row['provincia']}, {row['pais']}"
            status_label.config(text=f"Procesando: {address[:50]}...")
            progress_label.config(text=f"{contador} / {total_rows} ({current_progress:.1f}%)")
            
            # Actualizar la interfaz
            progress_window.update()
            
            # Geocodificar la direcci√≥n
            location = geocode_with_retry(address)
            if location:
                latitudes.append(location.latitude)
                longitudes.append(location.longitude)
                addresses.append(location.address)
                status_label.config(text=f"‚úÖ Encontrada: {location.address[:50]}...", fg="#10B981")
            else:
                latitudes.append(None)
                longitudes.append(None)
                addresses.append(None)
                status_label.config(text=f"‚ùå No encontrada: {address[:50]}...", fg="#EF4444")
            
            # Peque√±a pausa para que se vea la actualizaci√≥n
            progress_window.update()
            sleep(0.1)

        # Finalizar progreso
        progress_var.set(100)
        status_label.config(text="Guardando resultados...", fg="blue")
        progress_label.config(text=f"{total_rows} / {total_rows} (100%)")
        progress_window.update()

        self.df['Latitude'] = latitudes
        self.df['Longitude'] = longitudes
        self.df['GeocodedAddress'] = addresses

        geocoded_file = OUTPUT_DIR / "geocodificado.csv"
        self.df.to_csv(geocoded_file, index=False)
        logging.info(f"Archivo CSV geocodificado guardado en {geocoded_file}")

        # Mostrar estad√≠sticas finales
        successful_geocodes = sum(1 for lat in latitudes if lat is not None)
        failed_geocodes = total_rows - successful_geocodes
        
        status_label.config(text=f"üéâ Completado: {successful_geocodes} exitosas, {failed_geocodes} fallidas", fg="#10B981")
        progress_window.update()
        
        # Esperar un momento antes de cerrar
        sleep(1)
        progress_window.destroy()

        explanation = (
            "üó∫Ô∏è GEOCODIFICACI√ìN DE DIRECCIONES\n\n"
            "Este proceso convierte direcciones de texto en coordenadas GPS (latitud y longitud).\n\n"
            "üîç ¬øQU√â HACE?\n"
            "   ‚Ä¢ Toma direcciones como 'Provincia X, Pa√≠s Y'\n"
            "   ‚Ä¢ Las convierte en n√∫meros de ubicaci√≥n\n"
            "   ‚Ä¢ Agrega columnas de Latitude y Longitude\n\n"
            "üí° ¬øPARA QU√â SIRVE?\n"
            "   ‚Ä¢ Crear mapas con tus datos\n"
            "   ‚Ä¢ Ver d√≥nde est√°n ubicadas las cosas\n"
            "   ‚Ä¢ An√°lisis geogr√°fico de producci√≥n agr√≠cola"
        )
        
        messagebox.showinfo("Geocodificaci√≥n", 
                           f"Geocodificaci√≥n completada.\n"
                           f"Direcciones procesadas: {total_rows}\n"
                           f"Geocodificaciones exitosas: {successful_geocodes}\n"
                           f"Geocodificaciones fallidas: {failed_geocodes}\n"
                           f"Archivo guardado en: {geocoded_file}\n\n{explanation}")

    def generar_mapa(self):
        """Genera un mapa con las direcciones geocodificadas."""
        if not self._check_csv_loaded():
            return
        if 'Latitude' not in self.df.columns or 'Longitude' not in self.df.columns:
            messagebox.showwarning("Advertencia", "Por favor, geocodifique las direcciones primero.")
            return

        centro = [self.df['Latitude'].mean(), self.df['Longitude'].mean()]
        mapa = folium.Map(location=centro, zoom_start=6)

        for _, row in self.df.iterrows():
            if pd.notna(row['Latitude']) and pd.notna(row['Longitude']):
                folium.Marker(
                    location=[row['Latitude'], row['Longitude']],
                    popup=f"Provincia: {row['provincia']}, Departamento: {row['departamento']}, Cultivo: {row['cultivo']}",
                ).add_to(mapa)

        mapa_file = OUTPUT_DIR / "mapa_geoespacial.html"
        mapa.save(mapa_file)
        logging.info(f"Mapa geoespacial guardado en {mapa_file}")

        webbrowser.open(mapa_file.resolve().as_uri())

        explanation = (
            "üó∫Ô∏è MAPA GEOESPACIAL\n\n"
            "Este an√°lisis crea un mapa interactivo con puntos en las ubicaciones de tus datos.\n\n"
            "üîç ¬øQU√â VER√ÅS?\n"
            "   ‚Ä¢ Puntos en el mapa = ubicaciones de tus datos\n"
            "   ‚Ä¢ Al hacer clic en un punto = Provincia, Departamento y Cultivo\n\n"
            "üí° ¬øPARA QU√â SIRVE?\n"
            "   ‚Ä¢ Ver d√≥nde se produce m√°s agricultura\n"
            "   ‚Ä¢ Identificar patrones geogr√°ficos\n"
            "   ‚Ä¢ Planificar distribuci√≥n de recursos"
        )
        messagebox.showinfo("Generar Mapa", f"Mapa generado exitosamente.\n\n{explanation}")

    def mapa_distribucion_cultivos(self):
        """Genera un mapa del mundo mostrando la distribuci√≥n de cultivos con colores diferenciados."""
        if not self._check_csv_loaded():
            return
        if 'Latitude' not in self.df.columns or 'Longitude' not in self.df.columns or 'cultivo' not in self.df.columns:
            messagebox.showwarning("Advertencia", "Por favor, geocodifique las direcciones primero y aseg√∫rese de tener la columna 'cultivo'.")
            return

        # Filtrar datos con coordenadas v√°lidas
        df_mapa = self.df.dropna(subset=['Latitude', 'Longitude', 'cultivo'])

        if df_mapa.empty:
            messagebox.showwarning("Advertencia", "No hay datos v√°lidos con coordenadas y cultivos para mostrar en el mapa.")
            return

        # Crear mapa centrado en el mundo
        mapa = folium.Map(location=[0, 0], zoom_start=2)

        # Obtener cultivos √∫nicos y asignar colores
        cultivos_unicos = df_mapa['cultivo'].unique()
        colores = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred', 'beige', 'darkblue', 'darkgreen',
                   'cadetblue', 'darkpurple', 'white', 'pink', 'lightblue', 'lightgreen', 'gray', 'black', 'lightgray']

        color_dict = {}
        for i, cultivo in enumerate(cultivos_unicos):
            color_dict[cultivo] = colores[i % len(colores)]

        # Agregar marcadores para cada punto de datos
        for _, row in df_mapa.iterrows():
            cultivo = row['cultivo']
            color = color_dict[cultivo]
            folium.CircleMarker(
                location=[row['Latitude'], row['Longitude']],
                radius=5,
                popup=f"Cultivo: {cultivo}<br>Provincia: {row.get('provincia', 'N/A')}<br>Departamento: {row.get('departamento', 'N/A')}",
                color=color,
                fill=True,
                fill_color=color,
                fill_opacity=0.7
            ).add_to(mapa)

        # Agregar leyenda
        legend_html = '''
        <div style="position: fixed;
                    bottom: 50px; left: 50px; width: 200px; height: auto;
                    background-color: white; border:2px solid grey; z-index:9999; font-size:14px;
                    padding: 10px">
        <p><b>Leyenda de Cultivos</b></p>
        '''
        for cultivo, color in color_dict.items():
            legend_html += f'<p><span style="color:{color};">&#9679;</span> {cultivo}</p>'
        legend_html += '</div>'

        mapa.get_root().html.add_child(folium.Element(legend_html))

        mapa_file = OUTPUT_DIR / "mapa_distribucion_cultivos.html"
        mapa.save(mapa_file)
        logging.info(f"Mapa de distribuci√≥n de cultivos guardado en {mapa_file}")

        webbrowser.open(mapa_file.resolve().as_uri())

        explanation = (
            "üåç MAPA DE DISTRIBUCI√ìN DE CULTIVOS\n\n"
            "Este mapa muestra la distribuci√≥n mundial de tus cultivos agr√≠colas, "
            "con cada tipo de cultivo representado por un color diferente.\n\n"
            "üîç ¬øQU√â VER√ÅS?\n"
            "   ‚Ä¢ Puntos coloreados = ubicaciones de cultivos\n"
            "   ‚Ä¢ Cada color representa un tipo de cultivo diferente\n"
            "   ‚Ä¢ Leyenda en la esquina inferior izquierda\n\n"
            "üí° ¬øPARA QU√â SIRVE?\n"
            "   ‚Ä¢ Ver d√≥nde se cultivan diferentes productos\n"
            "   ‚Ä¢ Identificar patrones globales de agricultura\n"
            "   ‚Ä¢ Analizar diversidad agr√≠cola por regi√≥n"
        )
        messagebox.showinfo("Mapa de Distribuci√≥n de Cultivos", f"Mapa generado exitosamente.\n\n{explanation}")

    def produccion_top_cultivos(self):
        """Genera un gr√°fico de l√≠neas para los 4 principales cultivos por producci√≥n total."""
        if not self._check_csv_loaded():
            return
        if 'cultivo' not in self.df.columns or 'campa√±a' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'cultivo', 'campa√±a' y 'produccion'.")
            return

        # Agrupar los datos por cultivo y campa√±a, y sumar la producci√≥n
        grouped_data = self.df.groupby(['cultivo', 'campa√±a'])['produccion'].sum().reset_index()

        # Obtener los 4 principales cultivos por producci√≥n total
        top_cultivos = grouped_data.groupby('cultivo')['produccion'].sum().nlargest(4).index

        # Filtrar los datos para incluir solo los 4 cultivos principales
        filtered_data = grouped_data[grouped_data['cultivo'].isin(top_cultivos)]

        # Crear un gr√°fico de l√≠neas que muestre la producci√≥n por campa√±a para los 4 cultivos principales
        plt.figure(figsize=(12, 8))
        for cultivo in top_cultivos:
            cultivo_data = filtered_data[filtered_data['cultivo'] == cultivo]
            plt.plot(cultivo_data['campa√±a'], cultivo_data['produccion'], marker='o', label=cultivo)

        plt.title('Producci√≥n de los 4 principales cultivos por campa√±a')
        plt.xlabel('Campa√±a')
        plt.ylabel('Producci√≥n (en toneladas)')
        plt.xticks(rotation=45)
        plt.legend(title='Cultivo')
        plt.grid(True)
        plt.suptitle("produccion_top_cultivos", fontsize=10, y=0.98, ha='left', x=0.02, style='italic', alpha=0.7)
        plt.tight_layout()

        output_file = OUTPUT_DIR / "produccion_top_cultivos.png"
        plt.savefig(output_file)
        plt.show()
        logging.info(f"Gr√°fica de producci√≥n de los 4 principales cultivos guardada en {output_file}")

        explanation = (
            "üå± PRODUCCI√ìN DE LOS 4 CULTIVOS PRINCIPALES\n\n"
            "Esta gr√°fica muestra c√≥mo ha cambiado la producci√≥n de los cultivos m√°s importantes con el tiempo.\n\n"
            "üîç ¬øQU√â VER?\n"
            "   ‚Ä¢ L√≠neas que suben = producci√≥n aumentando\n"
            "   ‚Ä¢ L√≠neas que bajan = producci√≥n disminuyendo\n"
            "   ‚Ä¢ Cada color representa un cultivo diferente\n\n"
            "üí° ¬øPARA QU√â SIRVE?\n"
            "   ‚Ä¢ Saber qu√© cultivos est√°n de moda\n"
            "   ‚Ä¢ Planificar qu√© sembrar en el futuro\n"
            "   ‚Ä¢ Tomar decisiones de inversi√≥n"
        )
        messagebox.showinfo("Producci√≥n Top Cultivos", f"Gr√°fica guardada en {output_file}\n\n{explanation}")


    def mostrar_dialogo_informes(self):
        """Muestra un cuadro de di√°logo para seleccionar y generar informes."""
        informes = ["Producci√≥n Total por Provincia", "Correlaci√≥n Sup. Sembrada-Sup. Cosechada", "Sumar Columnas", 
                    "An√°lisis Temporal", "An√°lisis de Correlaci√≥n", "Modelos Predictivos", 
                    "Clasificaci√≥n de Cultivos", "An√°lisis de Riesgos", "Evoluci√≥n de Cultivos por Campa√±a", 
                    "Tendencias de Producci√≥n por Cultivo", "Predicci√≥n de Tendencias con IA",
                    "An√°lisis Predictivo con Red Neuronal", "Producci√≥n Top Cultivos"]

        selected_informe = self.ask_option("Generar Informe", "Seleccione el informe a generar:", informes)
        if selected_informe:
            getattr(self, self.get_function_name_from_report(selected_informe))()

    @staticmethod
    def get_function_name_from_report(report_name):
        """Devuelve el nombre de la funci√≥n correspondiente a un informe seleccionado."""
        function_mapping = {
            "Producci√≥n Total por Provincia": "produccion_total_por_provincia",
            "Correlaci√≥n Sup. Sembrada-Sup. Cosechada": "correlacion_sup_sembrada_cosechada",
            "Sumar Columnas": "sumar_columnas",
            "An√°lisis Temporal": "analisis_temporal",
            "An√°lisis de Correlaci√≥n": "analisis_correlacion",
            "Modelos Predictivos": "modelos_predictivos",
            "Clasificaci√≥n de Cultivos": "clasificacion_cultivos",
            "An√°lisis de Riesgos": "analisis_riesgos",
            "Evoluci√≥n de Cultivos por Campa√±a": "evolucion_cultivos_por_campa√±a",
            "Tendencias de Producci√≥n por Cultivo": "tendencias_produccion_por_cultivo",
            "Predicci√≥n de Tendencias con IA": "prediccion_tendencias_ia",
            "An√°lisis Predictivo con Red Neuronal": "analisis_predictivo_nn",
            "Producci√≥n Top Cultivos": "produccion_top_cultivos",
        }
        return function_mapping.get(report_name, "")

    def ask_option(self, title, message, options):
        """Muestra un cuadro de di√°logo para seleccionar una opci√≥n."""
        dialog = tk.Toplevel(self.root)
        dialog.title(title)
        dialog.geometry("250x150")
        dialog.resizable(False, False)

        label = tk.Label(dialog, text=message)
        label.pack(pady=10)

        combobox_value = tk.StringVar()
        combobox = ttk.Combobox(dialog, textvariable=combobox_value, values=options)
        combobox.pack(pady=10)
        combobox.current(0)

        button = ttk.Button(dialog, text="Aceptar", command=dialog.destroy)
        button.pack(pady=10)

        dialog.grab_set()
        dialog.wait_window()

        selected_option = combobox_value.get()
        return selected_option

    @staticmethod
    def safe_file_name(name):
        """Devuelve un nombre de archivo seguro para usar en el sistema de archivos."""
        return re.sub(r'[^\w\s-]', '', name).strip().replace(' ', '_')
 
 
 
if __name__ == "__main__":
    app = DataAnalyzer()
    app.root.mainloop()
