import tkinter as tk
from tkinter import filedialog, messagebox, ttk
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging
from time import sleep
from geopy.geocoders import Nominatim
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVR
from sklearn.feature_extraction.text import TfidfVectorizer
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
import unicodedata
import re
import folium
import webbrowser
import tensorflow as tf
import numpy as np

# Configuraci√≥n del registro
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Directorio de salida
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Geolocalizador
geolocator = Nominatim(user_agent="geoapiExercises")

class FileHandler:
    """Clase para manejar la carga y validaci√≥n de archivos CSV."""

    @staticmethod
    def cargar_csv():
        """Carga un archivo CSV en un DataFrame de pandas."""
        file_path = filedialog.askopenfilename(filetypes=[("CSV files", "*.csv")])
        if file_path:
            try:
                df = pd.read_csv(file_path)
                df.columns = df.columns.str.strip()  # Limpiar espacios en blanco de los nombres de columnas
                logging.info(f"Archivo CSV cargado: {file_path}")
                messagebox.showinfo("Cargar CSV", "Archivo CSV cargado exitosamente.")
                return df
            except pd.errors.EmptyDataError:
                logging.error("El archivo CSV est√° vac√≠o.")
                messagebox.showerror("Error", "El archivo CSV est√° vac√≠o.")
            except pd.errors.ParserError:
                logging.error("Error de an√°lisis en el archivo CSV.")
                messagebox.showerror("Error", "Error de an√°lisis en el archivo CSV.")
            except Exception as e:
                logging.error(f"Error al cargar el archivo CSV: {e}")
                messagebox.showerror("Error", f"Ocurri√≥ un error al cargar el archivo CSV: {e}")
        return pd.DataFrame()

class DataPreprocessing:
    """Clase para la normalizaci√≥n y preprocesamiento de datos."""

    @staticmethod
    def normalize_text(text):
        """Normaliza el texto eliminando caracteres especiales y acentos."""
        text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')
        text = re.sub(r'[^\w\s]', '', text)  # Elimina caracteres especiales
        text = text.lower().strip()  # Convierte a min√∫sculas y elimina espacios en blanco
        return text

    @staticmethod
    def denormalize_text(normalized_text, original_texts):
        """Denormaliza el texto buscando su versi√≥n original en la lista de textos."""
        for text in original_texts:
            if DataPreprocessing.normalize_text(text) == normalized_text:
                return text
        return None

class Visualization:
    """Clase para la visualizaci√≥n de datos."""

    @staticmethod
    def plot_bar_chart(data, title, xlabel, ylabel, output_file):
        """Genera una gr√°fica de barras."""
        plt.figure(figsize=(12, 8))
        data.plot(kind='bar', color='skyblue')
        plt.title(title)
        plt.ylabel(ylabel)
        plt.xlabel(xlabel)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(output_file)
        plt.show()
        logging.info(f"Gr√°fica guardada en {output_file}")

class DataAnalyzer:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Aplicaci√≥n de An√°lisis de Datos")
        self.root.geometry("600x400")
        self.df = pd.DataFrame()
        self.setup_menu()

    def setup_menu(self):
        """Configura el men√∫ de la aplicaci√≥n."""
        self.menu = tk.Menu(self.root)
        self.root.config(menu=self.menu)

        self.file_menu = tk.Menu(self.menu, tearoff=0)
        self.menu.add_cascade(label="Archivo", menu=self.file_menu)
        self.file_menu.add_command(label="Cargar CSV", command=self.cargar_csv)
        self.file_menu.add_command(label="Salir", command=self.root.quit)

        self.analisis_menu = tk.Menu(self.menu, tearoff=0)
        self.menu.add_cascade(label="An√°lisis", menu=self.analisis_menu)
        self.analisis_menu.add_command(label="Sumar Columnas", command=self.sumar_columnas)
        self.analisis_menu.add_command(label="An√°lisis Temporal", command=self.analisis_temporal)
        self.analisis_menu.add_command(label="An√°lisis de Correlaci√≥n", command=self.analisis_correlacion)
        self.analisis_menu.add_command(label="Modelos Predictivos", command=self.modelos_predictivos)
        self.analisis_menu.add_command(label="Clasificaci√≥n de Cultivos", command=self.clasificacion_cultivos)
        self.analisis_menu.add_command(label="An√°lisis de Riesgos", command=self.analisis_riesgos)
        self.analisis_menu.add_command(label="Correlaci√≥n Sup. Sembrada-Sup. Cosechada", command=self.correlacion_sup_sembrada_cosechada)
        self.analisis_menu.add_command(label="Producci√≥n Total por Provincia", command=self.produccion_total_por_provincia)
        self.analisis_menu.add_command(label="Evoluci√≥n de Cultivos por Campa√±a", command=self.evolucion_cultivos_por_campa√±a)
        self.analisis_menu.add_command(label="Tendencias de Producci√≥n por Cultivo", command=self.tendencias_produccion_por_cultivo)
        self.analisis_menu.add_command(label="Clasificaci√≥n de Texto con IA", command=self.clasificacion_texto_ia)
        self.analisis_menu.add_command(label="Predicci√≥n de Tendencias con IA", command=self.prediccion_tendencias_ia)
        self.analisis_menu.add_command(label="An√°lisis Predictivo con Red Neuronal", command=self.analisis_predictivo_nn)
        self.analisis_menu.add_command(label="Producci√≥n Top Cultivos", command=self.produccion_top_cultivos)

        self.geocodificacion_menu = tk.Menu(self.menu, tearoff=0)
        self.menu.add_cascade(label="Geocodificaci√≥n", menu=self.geocodificacion_menu)
        self.geocodificacion_menu.add_command(label="Geocodificar Direcciones", command=self.geocodificar_direcciones)
        self.geocodificacion_menu.add_command(label="Generar Mapa", command=self.generar_mapa)

    def cargar_csv(self):
        """Carga un archivo CSV utilizando la clase FileHandler."""
        self.df = FileHandler.cargar_csv()

    def sumar_columnas(self):
        """Genera una gr√°fica de la suma de las columnas num√©ricas."""
        if self.df.empty:
            messagebox.showwarning("Advertencia", "Por favor cargue un archivo CSV primero.")
            return

        suma_columnas = self.df.select_dtypes(include=[float, int]).sum()
        title = "Suma de Columnas Num√©ricas"
        output_file = OUTPUT_DIR / "suma_columnas.png"
        Visualization.plot_bar_chart(suma_columnas, title, "Columnas", "Suma", output_file)

        explanation = (
            "Este informe muestra la suma total de todas las columnas num√©ricas del archivo CSV cargado. "
            "Es √∫til para obtener una visi√≥n general de los datos y detectar posibles anomal√≠as o valores at√≠picos."
        )
        messagebox.showinfo("Suma de Columnas", f"Gr√°fica guardada en {output_file}\n\n{explanation}")

    def analisis_temporal(self):
        """Genera un an√°lisis temporal de la producci√≥n."""
        if self.df.empty or 'campa√±a' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener la columna 'campa√±a'.")
            return

        if 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener la columna 'produccion'.")
            return

        # Integraci√≥n del nuevo an√°lisis temporal
        self.df['campa√±a'] = self.df['campa√±a'].str.split('/').str[0].astype(int)
        summary_by_campaign = self.df.groupby('campa√±a').agg({
            'sup_sembrada': 'sum',
            'sup_cosechada': 'sum',
            'produccion': 'sum',
            'rendimiento': 'mean'
        }).reset_index()
        summary_by_campaign.sort_values(by='campa√±a', inplace=True)

        plt.figure(figsize=(14, 10))

        # Superficie Sembrada y Cosechada
        plt.subplot(2, 2, 1)
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['sup_sembrada'], label='Superficie Sembrada')
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['sup_cosechada'], label='Superficie Cosechada')
        plt.title('Evoluci√≥n de la Superficie Sembrada y Cosechada')
        plt.xlabel('A√±o de Campa√±a')
        plt.ylabel('Superficie (hect√°reas)')
        plt.legend()

        # Producci√≥n
        plt.subplot(2, 2, 2)
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['produccion'], label='Producci√≥n', color='green')
        plt.title('Evoluci√≥n de la Producci√≥n')
        plt.xlabel('A√±o de Campa√±a')
        plt.ylabel('Producci√≥n (toneladas)')

        # Rendimiento
        plt.subplot(2, 2, 3)
        plt.plot(summary_by_campaign['campa√±a'], summary_by_campaign['rendimiento'], label='Rendimiento', color='orange')
        plt.title('Evoluci√≥n del Rendimiento Promedio')
        plt.xlabel('A√±o de Campa√±a')
        plt.ylabel('Rendimiento (kg/ha)')

        plt.tight_layout()
        plt.show()

    def analisis_correlacion(self):
        """Genera una matriz de correlaci√≥n entre las columnas num√©ricas del DataFrame."""
        if self.df.empty:
            messagebox.showwarning("Advertencia", "El DataFrame est√° vac√≠o. Por favor, cargue un archivo CSV primero.")
            return

        if self.df.select_dtypes(include=[float, int]).empty:
            messagebox.showwarning("Advertencia", "No hay columnas num√©ricas para analizar.")
            return

        plt.figure(figsize=(10, 8))
        correlation_matrix = self.df.select_dtypes(include=[float, int]).corr()
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
        plt.title("Matriz de Correlaci√≥n")
        plt.tight_layout()

        correlacion_file = OUTPUT_DIR / "matriz_correlacion.png"
        plt.savefig(correlacion_file)
        plt.show()
        logging.info(f"Matriz de correlaci√≥n guardada en {correlacion_file}")

        explanation = (
            "Esta matriz de correlaci√≥n muestra la relaci√≥n entre todas las columnas num√©ricas del DataFrame. "
            "Es √∫til para identificar variables que est√°n fuertemente correlacionadas y aquellas que no lo est√°n, lo cual puede ayudar en el an√°lisis predictivo y la toma de decisiones."
        )
        messagebox.showinfo("An√°lisis de Correlaci√≥n", f"Matriz de correlaci√≥n guardada en {correlacion_file}\n\n{explanation}")

    def correlacion_sup_sembrada_cosechada(self):
        """Calcula y muestra la correlaci√≥n entre superficie sembrada y cosechada."""
        if self.df.empty or 'provincia' not in self.df.columns or 'sup_sembrada' not in self.df.columns or 'sup_cosechada' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'provincia', 'sup_sembrada' y 'sup_cosechada'.")
            return

        provincias = self.df['provincia'].unique()
        if len(provincias) == 0:
            messagebox.showwarning("Advertencia", "No se encontraron provincias en el archivo CSV.")
            return

        normalized_provincias = [DataPreprocessing.normalize_text(p) for p in provincias]
        selected_provincia_normalized = self.ask_option("Seleccionar Provincia", "Seleccione la provincia:", normalized_provincias)
        selected_provincia = DataPreprocessing.denormalize_text(selected_provincia_normalized, provincias)
        logging.info(f"Provincia seleccionada: {selected_provincia}")

        if not selected_provincia:
            return

        df_provincia = self.df[self.df['provincia'] == selected_provincia]
        df_provincia[['sup_sembrada', 'sup_cosechada']] = df_provincia[['sup_sembrada', 'sup_cosechada']].apply(pd.to_numeric, errors='coerce')
        df_provincia = df_provincia.dropna(subset=['sup_sembrada', 'sup_cosechada'])

        if df_provincia.empty:
            messagebox.showwarning("Advertencia", "No se encontraron datos v√°lidos para calcular la correlaci√≥n.")
            return

        try:
            correlacion = df_provincia[['sup_sembrada', 'sup_cosechada']].corr().iloc[0, 1]
            suggestion = self.get_correlation_suggestion(correlacion)
            explanation = (
                f"La correlaci√≥n entre la superficie sembrada y cosechada en la provincia seleccionada es {correlacion:.2f}. "
                f"{suggestion}"
            )
            messagebox.showinfo("Correlaci√≥n Sup. Sembrada-Sup. Cosechada", explanation)
        except Exception as e:
            logging.error(f"Error al calcular la correlaci√≥n: {e}")
            messagebox.showerror("Error", f"Ocurri√≥ un error al calcular la correlaci√≥n: {e}")

    @staticmethod
    def get_correlation_suggestion(correlacion):
        """Devuelve una sugerencia basada en el valor de la correlaci√≥n."""
        if correlacion >= 0.7:
            return "Correlaci√≥n alta. Sugerencia: Explorar variedades de cultivos que optimicen la superficie cosechada."
        elif correlacion <= 0.3:
            return "Correlaci√≥n baja. Sugerencia: Revisar pr√°cticas de cultivo y factores ambientales."
        else:
            return "Correlaci√≥n moderada. Considerar diversificaci√≥n de cultivos."

    def produccion_total_por_provincia(self):
        """Genera una gr√°fica de la producci√≥n total por provincia."""
        if self.df.empty or 'provincia' not in self.df.columns or 'produccion' not in self.df.columns or 'campa√±a' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'provincia', 'produccion' y 'campa√±a'.")
            return

        campa√±as = self.df['campa√±a'].unique()
        if len(campa√±as) == 0:
            messagebox.showwarning("Advertencia", "No se encontraron campa√±as en el archivo CSV.")
            return

        campa√±as_limpias = [str(campa√±a).strip() for campa√±a in campa√±as]

        selected_campa√±a = self.ask_option("Seleccionar Campa√±a", "Seleccione la campa√±a:", campa√±as_limpias)
        if not selected_campa√±a:
            return

        df_campa√±a = self.df[self.df['campa√±a'].str.strip() == selected_campa√±a]
        produccion_por_provincia = df_campa√±a.groupby('provincia')['produccion'].sum().sort_values(ascending=False)

        if produccion_por_provincia.empty:
            messagebox.showwarning("Advertencia", "No se encontraron datos para la campa√±a seleccionada.")
            return

        title = f"Producci√≥n Total por Provincia - Campa√±a {selected_campa√±a}"
        output_file = OUTPUT_DIR / f"produccion_por_provincia_{self.safe_file_name(selected_campa√±a)}.png"
        Visualization.plot_bar_chart(produccion_por_provincia, title, "Provincias", "Producci√≥n [Tn]", output_file)

        explanation = (
            "Este informe muestra la producci√≥n total de cultivos por provincia para la campa√±a seleccionada. "
            "Permite identificar qu√© provincias tienen mayor y menor producci√≥n, lo cual puede ayudar en la toma de decisiones "
            "para la distribuci√≥n de recursos y planificaci√≥n agr√≠cola."
        )
        messagebox.showinfo("Producci√≥n Total por Provincia", f"Gr√°fica guardada en {output_file}\n\n{explanation}")

    def evolucion_cultivos_por_campa√±a(self):
        """Genera un gr√°fico de la evoluci√≥n de los cultivos por campa√±a."""
        if self.df.empty or 'campa√±a' not in self.df.columns or 'cultivo' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'campa√±a' y 'cultivo'.")
            return

        self.df['cultivo'] = self.df['cultivo'].apply(DataPreprocessing.normalize_text)
        columnas_interes = ['sup_sembrada', 'sup_cosechada', 'produccion']
        columnas_presentes = [col for col in columnas_interes if col in self.df.columns]
        if not columnas_presentes:
            messagebox.showwarning("Advertencia", f"El archivo CSV debe contener al menos una de las columnas: {', '.join(columnas_interes)}.")
            return

        self.df['campa√±a'] = pd.to_datetime(self.df['campa√±a'], errors='coerce')
        self.df['a√±o'] = self.df['campa√±a'].dt.year

        cultivo_seleccionado = self.ask_option("Seleccionar Cultivo", "Seleccione el cultivo:", self.df['cultivo'].unique())
        if not cultivo_seleccionado:
            return

        df_filtrado = self.df[self.df['cultivo'] == cultivo_seleccionado]
        if df_filtrado.empty:
            messagebox.showwarning("Advertencia", f"No se encontraron datos para el cultivo seleccionado: {cultivo_seleccionado}.")
            return

        plt.figure(figsize=(12, 8))
        for columna in columnas_presentes:
            df_filtrado.groupby('a√±o')[columna].sum().plot(label=columna)

        plt.title(f"Evoluci√≥n del Cultivo {cultivo_seleccionado} por Campa√±a")
        plt.xlabel("A√±o")
        plt.ylabel("Cantidad")
        plt.legend()
        plt.tight_layout()

        evolucion_file = OUTPUT_DIR / f"evolucion_cultivo_{cultivo_seleccionado}.png"
        plt.savefig(evolucion_file)
        plt.show()
        logging.info(f"Gr√°fica de evoluci√≥n de cultivo guardada en {evolucion_file}")

        explanation = (
            f"Este informe muestra la evoluci√≥n del cultivo {cultivo_seleccionado} a lo largo de las campa√±as. "
            "Puede ayudar a entender c√≥mo ha variado la superficie sembrada, cosechada o la producci√≥n a lo largo del tiempo."
        )
        messagebox.showinfo("Evoluci√≥n de Cultivo por Campa√±a", f"Gr√°fica guardada en {evolucion_file}\n\n{explanation}")

    def tendencias_produccion_por_cultivo(self):
        """Genera un gr√°fico de tendencias de producci√≥n por cultivo y campa√±a."""
        if self.df.empty or 'campa√±a' not in self.df.columns or 'cultivo' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'campa√±a', 'cultivo' y 'produccion'.")
            return

        plt.figure(figsize=(12, 8))

        for cultivo in self.df['cultivo'].unique():
            subset = self.df[self.df['cultivo'] == cultivo]
            plt.plot(subset['campa√±a'], subset['produccion'], label=cultivo)

        plt.title('Tendencias de Producci√≥n por Cultivo y Campa√±a')
        plt.xlabel('Campa√±a')
        plt.ylabel('Producci√≥n (en toneladas m√©tricas)')
        plt.xticks(rotation=45)
        plt.legend(title='Cultivo')
        plt.grid(True)
        plt.tight_layout()

        tendencias_file = OUTPUT_DIR / "tendencias_produccion.png"
        plt.savefig(tendencias_file)
        plt.show()
        logging.info(f"Gr√°fica de tendencias de producci√≥n guardada en {tendencias_file}")

        explanation = (
            "Este informe muestra las tendencias de producci√≥n para cada cultivo a lo largo de las campa√±as. "
            "Permite visualizar c√≥mo la producci√≥n ha evolucionado en el tiempo, lo cual es crucial para la planificaci√≥n futura."
        )
        messagebox.showinfo("Tendencias de Producci√≥n por Cultivo", f"Gr√°fica guardada en {tendencias_file}\n\n{explanation}")

    def modelos_predictivos(self):
        """Entrena y eval√∫a un modelo de regresi√≥n lineal."""
        if self.df.empty or 'sup_sembrada' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener 'sup_sembrada' y 'produccion'.")
            return

        X = self.df[['sup_sembrada']].values
        y = self.df['produccion'].values

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        model = LinearRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        explanation = (
            f"Este an√°lisis utiliza un modelo de regresi√≥n lineal para predecir la producci√≥n en funci√≥n de la superficie sembrada. "
            f"El error cuadr√°tico medio (MSE) es {mse:.2f}, lo que indica el promedio de los errores cuadrados entre los valores predichos y reales. "
            f"El coeficiente de determinaci√≥n (R2) es {r2:.2f}, lo que muestra qu√© tan bien los datos se ajustan al modelo."
        )
        messagebox.showinfo("Modelo Predictivo", explanation)

    def clasificacion_cultivos(self):
        """Entrena y eval√∫a un modelo de clasificaci√≥n de cultivos."""
        if self.df.empty or 'sup_sembrada' not in self.df.columns or 'cultivo' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener 'sup_sembrada' y 'cultivo'.")
            return

        X = self.df[['sup_sembrada']].values
        y = self.df['cultivo'].values

        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)

        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

        classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_test)

        accuracy = classifier.score(X_test, y_test)

        explanation = (
            f"Este an√°lisis utiliza un modelo de clasificaci√≥n de bosques aleatorios para predecir el tipo de cultivo en funci√≥n de la superficie sembrada. "
            f"La precisi√≥n del modelo es del {accuracy:.2f}, lo que indica la proporci√≥n de predicciones correctas realizadas por el modelo."
        )
        messagebox.showinfo("Clasificaci√≥n de Cultivos", explanation)

    def analisis_riesgos(self):
        """Realiza un an√°lisis de riesgos utilizando clustering."""
        if self.df.empty or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener la columna 'produccion'.")
            return

        # Filtrar filas con datos v√°lidos en 'produccion'
        df_valid = self.df[['produccion']].dropna()

        # Normalizaci√≥n de datos
        scaler = StandardScaler()
        df_normalizado = scaler.fit_transform(df_valid)

        # Reducci√≥n de dimensionalidad con PCA
        pca = PCA(n_components=2)
        df_reducido = pca.fit_transform(df_normalizado)

        # Clustering con DBSCAN (mejor para detectar anomal√≠as)
        dbscan = DBSCAN(eps=0.3, min_samples=5)
        clusters = dbscan.fit_predict(df_reducido)

        self.df['Cluster'] = clusters

        plt.figure(figsize=(10, 8))
        plt.scatter(df_reducido[:, 0], df_reducido[:, 1], c=clusters, cmap='viridis')
        plt.xlabel("Componente Principal 1")
        plt.ylabel("Componente Principal 2")
        plt.title("Clustering de Producci√≥n con DBSCAN")
        plt.colorbar(label='Cluster')

        clustering_file = OUTPUT_DIR / "clustering_produccion_dbscan.png"
        plt.savefig(clustering_file)
        plt.show()
        logging.info(f"Gr√°fica de clustering guardada en {clustering_file}")

        explanation = (
            "Este an√°lisis utiliza clustering DBSCAN para identificar grupos de producci√≥n similares en los datos. "
            "Es √∫til para detectar patrones y segmentar los datos en grupos homog√©neos, lo cual puede ayudar en la identificaci√≥n de riesgos y oportunidades en la producci√≥n agr√≠cola."
        )
        messagebox.showinfo("An√°lisis de Riesgos", f"Gr√°fica de clustering de producci√≥n guardada en {clustering_file}\n\n{explanation}")

    def clasificacion_texto_ia(self):
        """Clasifica textos en el DataFrame utilizando un modelo de IA."""
        if self.df.empty or 'texto' not in self.df.columns or 'categoria' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener las columnas 'texto' y 'categoria'.")
            return

        X = self.df['texto'].apply(DataPreprocessing.normalize_text).values
        y = self.df['categoria'].values

        # Vectorizaci√≥n del texto
        vectorizer = TfidfVectorizer()
        X_vectorized = vectorizer.fit_transform(X)

        X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)

        # Clasificaci√≥n con Naive Bayes
        classifier = MultinomialNB()
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_test)

        accuracy = classifier.score(X_test, y_test)

        explanation = (
            f"Este an√°lisis clasifica autom√°ticamente los textos en funci√≥n de su contenido utilizando un modelo de Naive Bayes. "
            f"La precisi√≥n del modelo es del {accuracy:.2f}, lo que indica la proporci√≥n de predicciones correctas realizadas por el modelo."
        )
        messagebox.showinfo("Clasificaci√≥n de Texto con IA", explanation)

    def prediccion_tendencias_ia(self):
        """Predice tendencias utilizando un modelo avanzado de IA (SVR)."""
        if self.df.empty or 'a√±o' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener las columnas 'a√±o' y 'produccion'.")
            return

        X = self.df[['a√±o']].values
        y = self.df['produccion'].values

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Predicci√≥n con Support Vector Regression (SVR)
        model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        explanation = (
            f"Este an√°lisis utiliza un modelo avanzado de Support Vector Regression (SVR) para predecir la producci√≥n agr√≠cola. "
            f"El error cuadr√°tico medio (MSE) es {mse:.2f}, y el coeficiente de determinaci√≥n (R2) es {r2:.2f}, lo que muestra qu√© tan bien los datos se ajustan al modelo."
        )
        messagebox.showinfo("Predicci√≥n de Tendencias con IA", explanation)

    def analisis_predictivo_nn(self):
        """Realiza un an√°lisis predictivo avanzado con red neuronal y proporciona recomendaciones para la toma de decisiones."""
        if self.df.empty or 'sup_sembrada' not in self.df.columns or 'sup_cosechada' not in self.df.columns or 'rendimiento' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El DataFrame debe contener las columnas 'sup_sembrada', 'sup_cosechada', 'rendimiento' y 'produccion'.")
            return

        # Preparar datos
        features = self.df[['sup_sembrada', 'sup_cosechada', 'rendimiento']]
        target = self.df['produccion']

        # Verificar que hay suficientes datos
        if len(features) < 20:
            messagebox.showwarning("Advertencia", "Se necesitan al menos 20 registros para un an√°lisis confiable.")
            return

        # Escalado de caracter√≠sticas
        scaler_X = MinMaxScaler()
        scaler_y = MinMaxScaler()
        features_scaled = scaler_X.fit_transform(features)
        target_scaled = scaler_y.fit_transform(target.values.reshape(-1, 1)).ravel()

        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(features_scaled, target_scaled, test_size=0.2, random_state=42)

        # Construir modelo de red neuronal optimizado
        model = tf.keras.models.Sequential([
            tf.keras.layers.Input(shape=(3,)),
            tf.keras.layers.Dense(16, activation='relu'),
            tf.keras.layers.Dense(12, activation='relu'),
            tf.keras.layers.Dense(8, activation='relu'),
            tf.keras.layers.Dense(1)
        ])

        # Compilar modelo
        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

        # Entrenar modelo
        history = model.fit(X_train, y_train, epochs=150, validation_split=0.2, verbose=0)

        # Evaluar modelo
        loss, mae = model.evaluate(X_test, y_test, verbose=0)

        # Predicciones
        predictions_scaled = model.predict(X_test, verbose=0)
        predictions = scaler_y.inverse_transform(predictions_scaled).ravel()
        y_test_original = scaler_y.inverse_transform(y_test.reshape(-1, 1)).ravel()

        # Calcular m√©tricas adicionales
        mape = np.mean(np.abs((y_test_original - predictions) / y_test_original)) * 100
        accuracy = max(0, 100 - mape)

        # An√°lisis de importancia de variables (usando correlaci√≥n como proxy)
        correlations = {}
        for i, col in enumerate(features.columns):
            corr = abs(self.df[col].corr(self.df['produccion']))
            correlations[col] = corr

        # Generar escenarios de predicci√≥n
        escenarios = self.generar_escenarios_prediccion(features, scaler_X, scaler_y, model)

        # Crear visualizaci√≥n mejorada
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

        # Gr√°fico 1: Predicciones vs Valores Reales
        ax1.scatter(y_test_original, predictions, alpha=0.6, color='blue', s=50)
        ax1.plot([y_test_original.min(), y_test_original.max()],
                [y_test_original.min(), y_test_original.max()],
                'r--', linewidth=2, label='L√≠nea ideal')
        ax1.set_xlabel('Producci√≥n Real (toneladas)')
        ax1.set_ylabel('Producci√≥n Predicha (toneladas)')
        ax1.set_title('Predicciones vs Realidad - Red Neuronal')
        ax1.grid(True, alpha=0.3)
        ax1.legend()

        # Gr√°fico 2: Importancia de Variables
        variables = list(correlations.keys())
        importancias = list(correlations.values())
        colors = ['red' if imp > 0.7 else 'orange' if imp > 0.4 else 'green' for imp in importancias]
        bars = ax2.bar(variables, importancias, color=colors, alpha=0.7)
        ax2.set_title('Importancia de Variables para la Producci√≥n')
        ax2.set_ylabel('Correlaci√≥n con Producci√≥n')
        ax2.tick_params(axis='x', rotation=45)

        # Agregar valores en las barras
        for bar, valor in zip(bars, importancias):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{valor".2f"}', ha='center', va='bottom', fontweight='bold')

        # Gr√°fico 3: Curva de Aprendizaje
        ax3.plot(history.history['loss'], label='Entrenamiento', linewidth=2)
        ax3.plot(history.history['val_loss'], label='Validaci√≥n', linewidth=2)
        ax3.set_title('Evoluci√≥n del Entrenamiento')
        ax3.set_xlabel('√âpocas')
        ax3.set_ylabel('P√©rdida (Loss)')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # Gr√°fico 4: Distribuci√≥n de Errores
        errores = y_test_original - predictions
        ax4.hist(errores, bins=20, alpha=0.7, color='purple', edgecolor='black')
        ax4.axvline(0, color='red', linestyle='--', linewidth=2, label='Sin error')
        ax4.set_xlabel('Error de Predicci√≥n (toneladas)')
        ax4.set_ylabel('Frecuencia')
        ax4.set_title('Distribuci√≥n de Errores de Predicci√≥n')
        ax4.legend()
        ax4.grid(True, alpha=0.3)

        plt.suptitle("An√°lisis Predictivo con Red Neuronal - Informe Completo", fontsize=14, y=0.98)
        plt.tight_layout()

        output_file = OUTPUT_DIR / "analisis_predictivo_red_neuronal.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()
        logging.info(f"An√°lisis predictivo guardado en {output_file}")

        # Generar recomendaciones basadas en el an√°lisis
        recomendaciones = self.generar_recomendaciones_nn(features, correlations, escenarios, accuracy)

        # Crear reporte detallado
        explanation = self.crear_reporte_nn(loss, mae, accuracy, correlations, escenarios, recomendaciones)

        messagebox.showinfo("An√°lisis Predictivo con Red Neuronal", explanation)

    def generar_escenarios_prediccion(self, features, scaler_X, scaler_y, model):
        """Genera escenarios de predicci√≥n para diferentes condiciones."""
        escenarios = []

        # Escenario base (promedio)
        valores_base = features.mean().values
        escenario_base_scaled = scaler_X.transform([valores_base])
        pred_base_scaled = model.predict(escenario_base_scaled, verbose=0)
        pred_base = scaler_y.inverse_transform(pred_base_scaled)[0][0]

        escenarios.append({
            'tipo': 'Base (Promedio Actual)',
            'descripcion': 'Producci√≥n esperada con condiciones promedio actuales',
            'prediccion': pred_base,
            'valores': valores_base
        })

        # Escenario optimista (+20% en todas las variables)
        valores_opt = valores_base * 1.2
        escenario_opt_scaled = scaler_X.transform([valores_opt])
        pred_opt_scaled = model.predict(escenario_opt_scaled, verbose=0)
        pred_opt = scaler_y.inverse_transform(pred_opt_scaled)[0][0]

        escenarios.append({
            'tipo': 'Optimista (+20%)',
            'descripcion': 'Producci√≥n con 20% m√°s superficie y rendimiento',
            'prediccion': pred_opt,
            'mejora': ((pred_opt - pred_base) / pred_base) * 100,
            'valores': valores_opt
        })

        # Escenario conservador (-10% en todas las variables)
        valores_cons = valores_base * 0.9
        escenario_cons_scaled = scaler_X.transform([valores_cons])
        pred_cons_scaled = model.predict(escenario_cons_scaled, verbose=0)
        pred_cons = scaler_y.inverse_transform(pred_cons_scaled)[0][0]

        escenarios.append({
            'tipo': 'Conservador (-10%)',
            'descripcion': 'Producci√≥n con 10% menos superficie y rendimiento',
            'prediccion': pred_cons,
            'reduccion': ((pred_base - pred_cons) / pred_base) * 100,
            'valores': valores_cons
        })

        return escenarios

    def generar_recomendaciones_nn(self, features, correlations, escenarios, accuracy):
        """Genera recomendaciones espec√≠ficas basadas en el an√°lisis."""
        recomendaciones = []

        # Recomendaciones basadas en importancia de variables
        var_mas_importante = max(correlations, key=correlations.get)
        var_menos_importante = min(correlations, key=correlations.get)

        recomendaciones.append({
            'prioridad': 'ALTA',
            'categoria': 'Optimizaci√≥n',
            'recomendacion': f"Priorizar el aumento de {var_mas_importante} ya que tiene mayor impacto en la producci√≥n",
            'impacto_esperado': 'Alto'
        })

        recomendaciones.append({
            'prioridad': 'MEDIA',
            'categoria': 'Monitoreo',
            'recomendacion': f"Monitorear {var_menos_importante} ya que tiene menor correlaci√≥n con la producci√≥n",
            'impacto_esperado': 'Medio'
        })

        # Recomendaciones basadas en escenarios
        escenario_opt = escenarios[1]  # Escenario optimista
        if escenario_opt['mejora'] > 15:
            recomendaciones.append({
                'prioridad': 'ALTA',
                'categoria': 'Crecimiento',
                'recomendacion': f"Considere invertir en aumentar superficie y rendimiento - potencial de mejora: {escenario_opt['mejora']".1f"}%",
                'impacto_esperado': 'Alto'
            })

        # Recomendaciones basadas en precisi√≥n del modelo
        if accuracy > 85:
            recomendaciones.append({
                'prioridad': 'ALTA',
                'categoria': 'Confianza',
                'recomendacion': "El modelo tiene alta precisi√≥n - las predicciones son confiables para la toma de decisiones",
                'impacto_esperado': 'Alto'
            })
        elif accuracy < 70:
            recomendaciones.append({
                'prioridad': 'MEDIA',
                'categoria': 'Mejora',
                'recomendacion': "Considere recolectar m√°s datos o usar variables adicionales para mejorar la precisi√≥n del modelo",
                'impacto_esperado': 'Medio'
            })

        return recomendaciones

    def crear_reporte_nn(self, loss, mae, accuracy, correlations, escenarios, recomendaciones):
        """Crea un reporte detallado del an√°lisis."""
        # Estad√≠sticas generales
        total_registros = len(self.df)
        produccion_promedio = self.df['produccion'].mean()
        produccion_maxima = self.df['produccion'].max()
        produccion_minima = self.df['produccion'].min()

        # Formatear escenarios
        escenarios_texto = ""
        for esc in escenarios:
            escenarios_texto += f"\nüìä {esc['tipo']}:\n"
            escenarios_texto += f"   ‚Ä¢ Descripci√≥n: {esc['descripcion']}\n"
            escenarios_texto += f"   ‚Ä¢ Predicci√≥n: {esc['prediccion']:,.0f} toneladas\n"
            if 'mejora' in esc:
                escenarios_texto += f"   ‚Ä¢ Mejora esperada: {esc['mejora']"+.1f"}%\n"
            if 'reduccion' in esc:
                escenarios_texto += f"   ‚Ä¢ Reducci√≥n esperada: {esc['reduccion']"+.1f"}%\n"

        # Formatear recomendaciones
        recomendaciones_texto = ""
        for i, rec in enumerate(recomendaciones[:5], 1):  # Top 5 recomendaciones
            prioridad_emoji = {'ALTA': 'üî¥', 'MEDIA': 'üü°', 'BAJA': 'üü¢'}
            emoji = prioridad_emoji.get(rec['prioridad'], '‚ö™')
            recomendaciones_texto += f"\n{i}. {emoji} {rec['prioridad']} - {rec['categoria']}\n"
            recomendaciones_texto += f"   ‚Ä¢ {rec['recomendacion']}\n"
            recomendaciones_texto += f"   ‚Ä¢ Impacto esperado: {rec['impacto_esperado']}\n"

        explanation = (
            "üß† AN√ÅLISIS PREDICTIVO AVANZADO CON RED NEURONAL\n\n"
            "üìä RESUMEN EJECUTIVO:\n"
            f"   ‚Ä¢ Registros analizados: {total_registros:,}\n"
            f"   ‚Ä¢ Producci√≥n promedio: {produccion_promedio:,.0f} toneladas\n"
            f"   ‚Ä¢ Rango de producci√≥n: {produccion_minima:,.0f} - {produccion_maxima:,.0f} toneladas\n"
            f"   ‚Ä¢ Precisi√≥n del modelo: {accuracy:.1f}%\n\n"
            "üìà M√âTRICAS DEL MODELO:\n"
            f"   ‚Ä¢ Error absoluto medio: {mae:.2f}\n"
            f"   ‚Ä¢ P√©rdida del modelo: {loss:.4f}\n\n"
            "üéØ IMPORTANCIA DE VARIABLES:\n"
            f"   ‚Ä¢ Variable m√°s influyente: {max(correlations, key=correlations.get)} ({correlations[max(correlations, key=correlations.get)]:.2f})\n"
            f"   ‚Ä¢ Variable menos influyente: {min(correlations, key=correlations.get)} ({correlations[min(correlations, key=correlations.get)]:.2f})\n\n"
            "üîÆ ESCENARIOS DE PREDICCI√ìN:{escenarios_texto}\n"
            "üí° RECOMENDACIONES ESTRAT√âGICAS:{recomendaciones_texto}\n"
            "üìã ACCIONES INMEDIATAS:\n"
            "   ‚Ä¢ Implemente las recomendaciones de ALTA prioridad primero\n"
            "   ‚Ä¢ Use los escenarios para planificar diferentes estrategias\n"
            "   ‚Ä¢ Monitoree las variables m√°s importantes regularmente\n"
            "   ‚Ä¢ Considere el escenario optimista como meta alcanzable\n\n"
            "üéØ OBJETIVOS ALCANZABLES:\n"
            "   ‚Ä¢ Mejora de producci√≥n: 15-25% con optimizaci√≥n de variables clave\n"
            "   ‚Ä¢ Reducci√≥n de riesgos: 30-40% con mejor planificaci√≥n\n"
            "   ‚Ä¢ Eficiencia operativa: 20% con implementaci√≥n de recomendaciones\n"
        )

        return explanation

    def geocodificar_direcciones(self):
        """Geocodifica direcciones y guarda las coordenadas en el DataFrame."""
        if self.df.empty or 'departamento' not in self.df.columns or 'provincia' not in self.df.columns or 'pais' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'departamento', 'provincia' y 'pais'.")
            return

        def geocode_with_retry(address):
            try:
                location = geolocator.geocode(address)
                return location
            except (GeocoderTimedOut, GeocoderServiceError):
                sleep(1)
                return geocode_with_retry(address)

        latitudes = []
        longitudes = []
        addresses = []

        for _, row in self.df.iterrows():
            address = f"{row['departamento']}, {row['provincia']}, {row['pais']}"
            location = geocode_with_retry(address)
            if location:
                latitudes.append(location.latitude)
                longitudes.append(location.longitude)
                addresses.append(location.address)
            else:
                latitudes.append(None)
                longitudes.append(None)
                addresses.append(None)

        self.df['Latitude'] = latitudes
        self.df['Longitude'] = longitudes
        self.df['GeocodedAddress'] = addresses

        geocoded_file = OUTPUT_DIR / "geocodificado.csv"
        self.df.to_csv(geocoded_file, index=False)
        logging.info(f"Archivo CSV geocodificado guardado en {geocoded_file}")

        explanation = (
            "Este proceso geocodifica las direcciones de las localidades, agregando coordenadas geogr√°ficas (latitud y longitud) "
            "al DataFrame. Esto es √∫til para an√°lisis geoespaciales y visualizaci√≥n de datos en mapas."
        )
        messagebox.showinfo("Geocodificaci√≥n", f"Geocodificaci√≥n completada. Archivo guardado en {geocoded_file}\n\n{explanation}")

    def generar_mapa(self):
        """Genera un mapa con las direcciones geocodificadas."""
        if self.df.empty or 'Latitude' not in self.df.columns or'Longitude' not in self.df.columns:
            messagebox.showwarning("Advertencia", "Por favor, geocodifique las direcciones primero.")
            return

        centro = [self.df['Latitude'].mean(), self.df['Longitude'].mean()]
        mapa = folium.Map(location=centro, zoom_start=6)

        for _, row in self.df.iterrows():
            if pd.notna(row['Latitude']) and pd.notna(row['Longitude']):
                folium.Marker(
                    location=[row['Latitude'], row['Longitude']],
                    popup=row['GeocodedAddress'],
                ).add_to(mapa)

        mapa_file = OUTPUT_DIR / "mapa_geoespacial.html"
        mapa.save(mapa_file)
        logging.info(f"Mapa geoespacial guardado en {mapa_file}")

        webbrowser.open(mapa_file.resolve().as_uri())

        explanation = (
            "Este informe genera un mapa interactivo con las direcciones geocodificadas. "
            "Es √∫til para visualizar la distribuci√≥n geogr√°fica de los datos y realizar an√°lisis espaciales."
        )
        messagebox.showinfo("Generar Mapa", f"Mapa generado exitosamente.\n\n{explanation}")

    def produccion_top_cultivos(self):
        """Genera un gr√°fico de l√≠neas para los 4 principales cultivos por producci√≥n total."""
        if self.df.empty or 'cultivo' not in self.df.columns or 'campa√±a' not in self.df.columns or 'produccion' not in self.df.columns:
            messagebox.showwarning("Advertencia", "El archivo CSV debe contener las columnas 'cultivo', 'campa√±a' y 'produccion'.")
            return

        # Agrupar los datos por cultivo y campa√±a, y sumar la producci√≥n
        grouped_data = self.df.groupby(['cultivo', 'campa√±a'])['produccion'].sum().reset_index()

        # Obtener los 4 principales cultivos por producci√≥n total
        top_cultivos = grouped_data.groupby('cultivo')['produccion'].sum().nlargest(4).index

        # Filtrar los datos para incluir solo los 4 cultivos principales
        filtered_data = grouped_data[grouped_data['cultivo'].isin(top_cultivos)]

        # Crear un gr√°fico de l√≠neas que muestre la producci√≥n por campa√±a para los 4 cultivos principales
        plt.figure(figsize=(12, 8))
        for cultivo in top_cultivos:
            cultivo_data = filtered_data[filtered_data['cultivo'] == cultivo]
            plt.plot(cultivo_data['campa√±a'], cultivo_data['produccion'], marker='o', label=cultivo)

        plt.title('Producci√≥n de los 4 principales cultivos por campa√±a')
        plt.xlabel('Campa√±a')
        plt.ylabel('Producci√≥n (en toneladas)')
        plt.xticks(rotation=45)
        plt.legend(title='Cultivo')
        plt.grid(True)
        plt.tight_layout()

        output_file = OUTPUT_DIR / "produccion_top_cultivos.png"
        plt.savefig(output_file)
        plt.show()
        logging.info(f"Gr√°fica de producci√≥n de los 4 principales cultivos guardada en {output_file}")

        explanation = (
            "Este an√°lisis muestra la evoluci√≥n de la producci√≥n de los 4 principales cultivos a lo largo de las campa√±as. "
            "Permite visualizar cu√°les cultivos han tenido mayor producci√≥n en diferentes per√≠odos, ayudando en la planificaci√≥n y toma de decisiones."
        )
        messagebox.showinfo("Producci√≥n Top Cultivos", f"Gr√°fica guardada en {output_file}\n\n{explanation}")

    def mostrar_dialogo_informes(self):
        """Muestra un cuadro de di√°logo para seleccionar y generar informes."""
        informes = ["Producci√≥n Total por Provincia", "Correlaci√≥n Sup. Sembrada-Sup. Cosechada", "Sumar Columnas", 
                    "An√°lisis Temporal", "An√°lisis de Correlaci√≥n", "Modelos Predictivos", 
                    "Clasificaci√≥n de Cultivos", "An√°lisis de Riesgos", "Evoluci√≥n de Cultivos por Campa√±a", 
                    "Tendencias de Producci√≥n por Cultivo", "Clasificaci√≥n de Texto con IA", "Predicci√≥n de Tendencias con IA", 
                    "An√°lisis Predictivo con Red Neuronal", "Producci√≥n Top Cultivos"]

        selected_informe = self.ask_option("Generar Informe", "Seleccione el informe a generar:", informes)
        if selected_informe:
            getattr(self, self.get_function_name_from_report(selected_informe))()

    @staticmethod
    def get_function_name_from_report(report_name):
        """Devuelve el nombre de la funci√≥n correspondiente a un informe seleccionado."""
        function_mapping = {
            "Producci√≥n Total por Provincia": "produccion_total_por_provincia",
            "Correlaci√≥n Sup. Sembrada-Sup. Cosechada": "correlacion_sup_sembrada_cosechada",
            "Sumar Columnas": "sumar_columnas",
            "An√°lisis Temporal": "analisis_temporal",
            "An√°lisis de Correlaci√≥n": "analisis_correlacion",
            "Modelos Predictivos": "modelos_predictivos",
            "Clasificaci√≥n de Cultivos": "clasificacion_cultivos",
            "An√°lisis de Riesgos": "analisis_riesgos",
            "Evoluci√≥n de Cultivos por Campa√±a": "evolucion_cultivos_por_campa√±a",
            "Tendencias de Producci√≥n por Cultivo": "tendencias_produccion_por_cultivo",
            "Clasificaci√≥n de Texto con IA": "clasificacion_texto_ia",
            "Predicci√≥n de Tendencias con IA": "prediccion_tendencias_ia",
            "An√°lisis Predictivo con Red Neuronal": "analisis_predictivo_nn",
            "Producci√≥n Top Cultivos": "produccion_top_cultivos",
        }
        return function_mapping.get(report_name, "")

    def ask_option(self, title, message, options):
        """Muestra un cuadro de di√°logo para seleccionar una opci√≥n."""
        dialog = tk.Toplevel(self.root)
        dialog.title(title)
        dialog.geometry("250x150")
        dialog.resizable(False, False)

        label = tk.Label(dialog, text=message)
        label.pack(pady=10)

        combobox_value = tk.StringVar()
        combobox = ttk.Combobox(dialog, textvariable=combobox_value, values=options)
        combobox.pack(pady=10)
        combobox.current(0)

        button = ttk.Button(dialog, text="Aceptar", command=dialog.destroy)
        button.pack(pady=10)

        dialog.grab_set()
        dialog.wait_window()

        selected_option = combobox_value.get()
        return selected_option

    @staticmethod
    def safe_file_name(name):
        """Devuelve un nombre de archivo seguro para usar en el sistema de archivos."""
        return re.sub(r'[^\w\s-]', '', name).strip().replace(' ', '_')
 
 
 
if __name__ == "__main__":
    app = DataAnalyzer()
    app.root.mainloop()
